{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc411f95ab0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1013)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"codegen.csv\")\n",
    "data_x = df[\"utterance\"]\n",
    "data_y = df[\"targets\"]\n",
    "\n",
    "\"\"\"\n",
    "# import dataset\n",
    "with open(\"calculator.dataset\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "data_x, data_y = [], []\n",
    "for line in lines:\n",
    "    if (line[0] == \"(\"):\n",
    "        data_y.append(line.strip())\n",
    "    elif (line != \"\\n\"):\n",
    "        data_x.append(line.strip())\n",
    "\"\"\"\n",
    "# split into test/train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.2)\n",
    "\n",
    "test_x.loc[38] = \"What is the minimum humidity?\"\n",
    "test_y.loc[38] = \"min( WeatherHistory [ 'Humidity' ] )\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building input and output vocabulary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NULL': 0, 'UNK': 1, '<end>': 2, 'What': 3, 'is': 4, 'the': 5, 'lowest': 6, 'temperature': 7, 'value?': 8, 'to': 9, 'how': 10, 'it': 11, 'Predict': 12, 'linear': 13, 'model': 14, 'when': 15, 'at': 16, '12': 17, 'degrees.': 18, 'Tell': 19, 'me': 20, 'what': 21, 'minimum': 22, 'What’s': 23, 'today?': 24, 'Can': 25, 'you': 26, 'average': 27, 'of': 28, 'all': 29, 'temperatures': 30, 'in': 31, 'weather': 32, 'history': 33, 'data': 34, 'base.': 35, 'temperature.': 36, \"What's\": 37, 'highest': 38, 'How': 39, 'does': 40, 'influence': 41, 'feeling_temperature?': 42, 'have': 43, 'affect': 44, 'on': 45, 'humidity?': 46, 'Give': 47, 'actual': 48, 'and': 49, 'feeling': 50, 'predict': 51, 'value': 52, 'humidity': 53, 'would': 54, 'relationship': 55, 'between': 56, 'Of': 57, 'listed': 58, 'values,': 59, 'which': 60, 'your': 61, 'prediction': 62, 'Calculate': 63, 'correlation': 64, 'variables': 65, 'correlated': 66, 'from': 67, 'temperature?': 68, 'feel': 69, 'like': 70, 'outside,': 71, 'tell': 72, 'recorded?': 73, '12.': 74, 'hot': 75, 'did': 76, 'get': 77, 'based': 78, 'dataset?': 79, 'will': 80, 'be': 81, \"it's\": 82, 'degrees': 83, 'celsius?': 84, 'was': 85, 'Please': 86, 'find': 87, 'coldest': 88, 'hottest': 89, 'day?': 90, 'mean': 91, 'give': 92, 'predicted': 93, 'values': 94, 'for': 95, 'described': 96, 'previous': 97, 'question.': 98, 'history?': 99, 'maximum': 100, 'a': 101, '12?': 102, 'Find': 103, 'forecasted': 104, 'any': 105, 'β̂': 106, 'using': 107, \"what's\": 108, 'Describe': 109, 'by': 110, 'Weather': 111, 'History': 112, 'At': 113, 'degrees,': 114, 'Do': 115, '_': 116, '_?': 117, 'cold': 118, 'get?': 119, 'regression': 120, 'predicting': 121, 'value.': 122, 'Which': 123, 'Create': 124, 'recorded': 125, 'WeatherHistory.': 126, 'WeatherHistory?': 127, 'there': 128, 'be?': 129, 'with': 130, 'level': 131, 'entry': 132, 'are': 133}\n",
      "{'NULL': 0, 'UNK': 1, '<end>': 2, 'min(': 3, 'WeatherHistory': 4, '[': 5, \"'Temperature'\": 6, ']': 7, ')': 8, 'cor(': 9, 'WeatherHistroy': 10, ',': 11, \"'FellingTemperature'\": 12, 'predict(': 13, 'mod': 14, '12': 15, 'max(': 16, 'mean(': 17, 'lm(': 18, \"'Humidity'\": 19}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class Vocabulary():\n",
    "    END_OF_SENTENCE = '<end>'\n",
    "    NULL = 'NULL'\n",
    "    UNKNOWN = 'UNK'\n",
    "    END_OF_SENTENCE_INDEX = 2\n",
    "    def __init__(self):\n",
    "        self.tok2ind = {self.NULL: 0, self.UNKNOWN: 1, self.END_OF_SENTENCE: 2}\n",
    "        self.ind2tok = {0: self.NULL, 1: self.UNKNOWN, 2: self.END_OF_SENTENCE}\n",
    "    \n",
    "    def add(self, token):\n",
    "        if token not in self.tok2ind:\n",
    "            index = len(self.tok2ind)\n",
    "            self.tok2ind[token] = index\n",
    "            self.ind2tok[index] = token\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tok2ind)\n",
    "    \n",
    "    def get_index(self, word):\n",
    "        if word in self.tok2ind:\n",
    "            return self.tok2ind[word]\n",
    "        return self.tok2ind[self.UNKNOWN]\n",
    "    \n",
    "    def get_word(self, i):\n",
    "        return self.ind2tok[i]\n",
    "\n",
    "    def sentence_to_indices(self, sentence):\n",
    "        words = [x for x in sentence.split(' ')]\n",
    "        words.append(self.END_OF_SENTENCE)\n",
    "        indices = [self.get_index(w) for w in words]\n",
    "        return indices\n",
    "\n",
    "def build_vocab(examples):\n",
    "    counts = Counter()\n",
    "    for ex in examples:\n",
    "        words = [w for w in ex.split(' ') if w.strip()]\n",
    "        counts.update(words)\n",
    "    \n",
    "    word_list = [w for w in counts if counts[w] > 1]\n",
    "    \n",
    "    word_dict = Vocabulary()\n",
    "    for w in word_list:\n",
    "        word_dict.add(w)\n",
    "    return word_dict\n",
    "\n",
    "input_vocab = build_vocab(train_x)\n",
    "output_vocab = build_vocab(train_y)\n",
    "print(input_vocab.tok2ind)\n",
    "print(output_vocab.tok2ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x7]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x10]\n",
      "\n",
      "\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  1  0\n",
      " 0  0  0  0  0  0\n",
      "[torch.FloatTensor of size 5x6]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 6x7]\n",
      "\n",
      "\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x6]\n",
      "\n",
      "\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x5]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x7]\n",
      "\n",
      "\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x6]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 5x9]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 5x12]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x10]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 6x10]\n",
      "\n",
      "\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x6]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 6x11]\n",
      "\n",
      "\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x6]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 5x10]\n",
      "\n",
      "\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x6]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     1     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 5x7]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x9]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 6x7]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x10]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x9]\n",
      "\n",
      "\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 13 \n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 11x14]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 6x11]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x9]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 6x7]\n",
      "\n",
      "\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x5]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x7]\n",
      "\n",
      "\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x6]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x10]\n",
      "\n",
      "\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x6]\n",
      "\n",
      "\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 17 \n",
      "    0     0     0     0     0\n",
      "    0     0     0     0     0\n",
      "    0     0     0     0     0\n",
      "    0     0     1     0     0\n",
      "    0     0     0     0     0\n",
      "[torch.FloatTensor of size 5x18]\n",
      "\n",
      "\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x5]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x8]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x8]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x8]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 6x12]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x11]\n",
      "\n",
      "\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "class Example():\n",
    "    def __init__(self, x_str, y_str, input_vocab, output_vocab):\n",
    "        self.x_str = x_str\n",
    "        self.y_str = y_str\n",
    "        self.x_toks = x_str.split(' ')\n",
    "        self.y_toks = y_str.split(' ')\n",
    "        \n",
    "        self.input_vocab = input_vocab\n",
    "        self.output_vocab = output_vocab\n",
    "        self.x_inds = torch.LongTensor(input_vocab.sentence_to_indices(x_str))\n",
    "        self.y_inds = torch.LongTensor(output_vocab.sentence_to_indices(y_str))\n",
    "        \n",
    "        # for copying\n",
    "        self.y_in_x_inds = torch.FloatTensor(([[int(x_tok == y_tok) for x_tok in self.x_toks] for y_tok in self.y_toks])) \n",
    "\n",
    "# In order to use PyTorch's data loader\n",
    "class ReaderDataset(Dataset):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.examples[index]\n",
    "    \n",
    "train_exs = []\n",
    "for x,y in zip(train_x, train_y):\n",
    "    train_exs.append(Example(x, y, input_vocab, output_vocab))\n",
    "train_dataset = ReaderDataset(train_exs)\n",
    "\n",
    "test_exs = []\n",
    "for x,y in zip(test_x, test_y):\n",
    "    test_exs.append(Example(x, y, input_vocab, output_vocab))\n",
    "test_dataset = ReaderDataset(test_exs)\n",
    "\n",
    "for x in test_dataset:\n",
    "    print(x.y_in_x_inds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize individual examples and organize them into batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "51\n",
      "(\n",
      "   25    26     1  ...      0     0     0\n",
      "  123    58     7  ...      0     0     0\n",
      "    3     4     5  ...      0     0     0\n",
      "       ...          ⋱          ...       \n",
      "    4   128   101  ...      0     0     0\n",
      "   39     1    40  ...      0     0     0\n",
      "   37     5    38  ...      0     0     0\n",
      "[torch.LongTensor of size 100x22]\n",
      ", \n",
      "   14\n",
      "   28\n",
      "   54\n",
      "   74\n",
      "   96\n",
      "  116\n",
      "  140\n",
      "  159\n",
      "  185\n",
      "  210\n",
      "  227\n",
      "  249\n",
      "  272\n",
      "  291\n",
      "  322\n",
      "  336\n",
      "  362\n",
      "  386\n",
      "  402\n",
      "  430\n",
      "  445\n",
      "  466\n",
      "  492\n",
      "  517\n",
      "  538\n",
      "  556\n",
      "  585\n",
      "  604\n",
      "  625\n",
      "  646\n",
      "  666\n",
      "  687\n",
      "  709\n",
      "  735\n",
      "  753\n",
      "  776\n",
      "  804\n",
      "  819\n",
      "  857\n",
      "  866\n",
      "  885\n",
      "  907\n",
      "  934\n",
      "  954\n",
      "  976\n",
      "  997\n",
      " 1021\n",
      " 1039\n",
      " 1062\n",
      " 1088\n",
      " 1108\n",
      " 1132\n",
      " 1150\n",
      " 1173\n",
      " 1194\n",
      " 1216\n",
      " 1241\n",
      " 1267\n",
      " 1288\n",
      " 1308\n",
      " 1325\n",
      " 1349\n",
      " 1370\n",
      " 1392\n",
      " 1416\n",
      " 1439\n",
      " 1456\n",
      " 1487\n",
      " 1503\n",
      " 1529\n",
      " 1546\n",
      " 1567\n",
      " 1591\n",
      " 1613\n",
      " 1633\n",
      " 1658\n",
      " 1677\n",
      " 1703\n",
      " 1723\n",
      " 1746\n",
      " 1764\n",
      " 1788\n",
      " 1814\n",
      " 1836\n",
      " 1859\n",
      " 1883\n",
      " 1901\n",
      " 1931\n",
      " 1941\n",
      " 1966\n",
      " 1989\n",
      " 2013\n",
      " 2030\n",
      " 2056\n",
      " 2080\n",
      " 2096\n",
      " 2122\n",
      " 2142\n",
      " 2162\n",
      " 2185\n",
      "[torch.LongTensor of size 100]\n",
      ", \n",
      "    0     0     0  ...      1     1     1\n",
      "    0     0     0  ...      1     1     1\n",
      "    0     0     0  ...      1     1     1\n",
      "       ...          ⋱          ...       \n",
      "    0     0     0  ...      1     1     1\n",
      "    0     0     0  ...      1     1     1\n",
      "    0     0     0  ...      1     1     1\n",
      "[torch.ByteTensor of size 100x22]\n",
      ", \n",
      "   17     4     5  ...      0     0     0\n",
      "   16     4     5  ...      0     0     0\n",
      "    9    10     5  ...      7     8     2\n",
      "       ...          ⋱          ...       \n",
      "    9    10     5  ...      7     8     2\n",
      "   16     4     5  ...      0     0     0\n",
      "    3     4     5  ...      0     0     0\n",
      "[torch.LongTensor of size 100x12]\n",
      ", \n",
      "    1     1     1  ...      0     0     0\n",
      "    1     1     1  ...      0     0     0\n",
      "    1     1     1  ...      1     1     1\n",
      "       ...          ⋱          ...       \n",
      "    1     1     1  ...      1     1     1\n",
      "    1     1     1  ...      0     0     0\n",
      "    1     1     1  ...      0     0     0\n",
      "[torch.ByteTensor of size 100x12]\n",
      ", \n",
      "( 0 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "\n",
      "( 1 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "\n",
      "( 2 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "... \n",
      "\n",
      "(97 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "\n",
      "(98 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "\n",
      "(99 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "[torch.FloatTensor of size 100x12x22]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# vectorize batch data\n",
    "def vectorize(batch):\n",
    "    max_input_length = max([ex.x_inds.size(0) for ex in batch])\n",
    "    x = torch.LongTensor(len(batch), max_input_length).zero_() # initialize to 0\n",
    "    x_mask = torch.ByteTensor(len(batch), max_input_length).fill_(1) # mask used in softmax\n",
    "    x_lens = torch.LongTensor(len(batch)).zero_()\n",
    "    for i, ex in enumerate(batch):\n",
    "        x[i, :ex.x_inds.size(0)].copy_(ex.x_inds)\n",
    "        x_mask[i, :ex.x_inds.size(0)].fill_(0)\n",
    "        ###CHANGE: x_lens store the last index of each sequence. i*max_input_length is added so that later we can use \n",
    "        ###torch.index_select to get the last hidden states from a 2D tensor (batch_size*max_input_length, embedding_dim)\n",
    "        x_lens[i] = i*max_input_length+ex.x_inds.size(0)-1 \n",
    "    \n",
    "    max_output_length = max([ex.y_inds.size(0) for ex in batch])\n",
    "    y = torch.LongTensor(len(batch), max_output_length).zero_()\n",
    "    y_mask = torch.ByteTensor(len(batch), max_output_length).zero_() # for masked_select\n",
    "    for i, ex in enumerate(batch):\n",
    "        y[i, :ex.y_inds.size(0)].copy_(ex.y_inds)\n",
    "        y_mask[i, :ex.y_inds.size(0)].fill_(1)\n",
    "    \n",
    "    # for copying\n",
    "    y_in_x_inds = torch.FloatTensor(len(batch), max_output_length, max_input_length).zero_()\n",
    "    for i, ex in enumerate(batch):\n",
    "        y_in_x_inds[i, :ex.y_in_x_inds.size(0), :ex.y_in_x_inds.size(1)].copy_(ex.y_in_x_inds)\n",
    "\n",
    "    return x, x_lens, x_mask, y, y_mask, y_in_x_inds\n",
    "\n",
    "train_sampler = torch.utils.data.sampler.RandomSampler(train_dataset)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=100, ## the batch_size can be tuned\n",
    "    sampler=train_sampler,\n",
    "    num_workers=1,\n",
    "    collate_fn=vectorize\n",
    ")\n",
    "\n",
    "test_sampler = torch.utils.data.sampler.SequentialSampler(test_dataset)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1, ## the batch_size can be tuned\n",
    "    sampler=test_sampler,\n",
    "    num_workers=1,\n",
    "    collate_fn=vectorize\n",
    ")\n",
    "\n",
    "for x in train_loader:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 Build the seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack bidirectional LSTM\n",
    "class StackBRNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers=1):\n",
    "        super(StackBRNN, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.rnns = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            input_dim = input_dim if i == 0 else hidden_dim * 2\n",
    "            self.rnns.append(nn.LSTM(input_dim, hidden_dim, bidirectional=True))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Transpose batch and sequence dims\n",
    "        x = x.transpose(0, 1) # (seq_len, batch_size, input_dim)\n",
    "\n",
    "        outputs = [x]\n",
    "        for i in range(self.num_layers):\n",
    "            rnn_input = outputs[-1]\n",
    "            rnn_output = self.rnns[i](rnn_input)[0]\n",
    "            outputs.append(rnn_output)\n",
    "\n",
    "        h_output = outputs[-1]\n",
    "\n",
    "        # Transpose back\n",
    "        h_output = h_output.transpose(0, 1) # (batch_size, seq_len, 2*hidden_dim)\n",
    "        \n",
    "        return h_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2.1: Define the basic seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, input_vocab, output_vocab, copying=False):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.input_vocab = input_vocab\n",
    "        self.output_vocab = output_vocab\n",
    "        self.in_vocab_size = len(self.input_vocab)\n",
    "        self.out_vocab_size = len(self.output_vocab)\n",
    "        \n",
    "        self.in_embedding = nn.Embedding(self.in_vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.encoder = StackBRNN(embedding_dim, hidden_dim)\n",
    "        \n",
    "        self.out_embedding = nn.Embedding(self.out_vocab_size, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        #Inputs: input, (h_0, c_0)\n",
    "        #Outputs: h_1, c_1\n",
    "        self.decoder = nn.LSTMCell(embedding_dim, hidden_dim) \n",
    "         \n",
    "        self.enc_to_dec = nn.Linear(hidden_dim*2, hidden_dim) # project encoding outupt\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_dim, self.out_vocab_size)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x_emb = self.in_embedding(x)\n",
    "        output = self.encoder(x_emb) # output: (batch_size, seq_len, hidden_dim*2)\n",
    "        return output\n",
    "    \n",
    "    def decode(self, h_prev):\n",
    "        out = self.output_layer(h_prev[0])\n",
    "        probs = F.softmax(out, dim=1)\n",
    "        \n",
    "        return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attention.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionSeq2Seq(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, input_vocab, output_vocab, copying=False):\n",
    "        super(AttentionSeq2Seq, self).__init__()\n",
    "        self.input_vocab = input_vocab\n",
    "        self.output_vocab = output_vocab\n",
    "        self.in_vocab_size = len(self.input_vocab)\n",
    "        self.out_vocab_size = len(self.output_vocab)\n",
    "        self.copying = copying\n",
    "        \n",
    "        self.in_embedding = nn.Embedding(self.in_vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.encoder = StackBRNN(embedding_dim, hidden_dim)\n",
    "        \n",
    "        self.out_embedding = nn.Embedding(self.out_vocab_size, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        #Inputs: input, (h_0, c_0)\n",
    "        #Outputs: h_1, c_1\n",
    "        self.decoder = nn.LSTMCell(embedding_dim + hidden_dim*2, hidden_dim) # concatenate y_t and context_t\n",
    "        \n",
    "        self.enc_to_dec = nn.Linear(hidden_dim*2, hidden_dim) # project encoding outupt\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_dim + hidden_dim*2, self.out_vocab_size) # concatenate h_t and context_t\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x_emb = self.in_embedding(x)\n",
    "        output = self.encoder(x_emb) # output: (batch_size, seq_len, hidden_dim*2)\n",
    "        return output\n",
    "    \n",
    "    def decode(self, encoder_outputs, encoder_proj_outputs, x_mask, h_prev):\n",
    "        # (batch_size, seq_len, hidden_dim) * (batch_size, hidden_dim, 1) - >(batch_size, seq_len, 1)\n",
    "        scores = torch.bmm(encoder_proj_outputs, h_prev[0].unsqueeze(2)).squeeze(2) # scores: (batch_size, seq_len)\n",
    "        scores.data.masked_fill_(x_mask.data, -float('inf'))\n",
    "        alpha = F.softmax(scores, dim=1)\n",
    "        # (batch_size, 1, seq_len) * (batch_size, seq_len, hidden_dim) - > (batch_size, 1, hidden_dim)\n",
    "        context_t = torch.bmm(alpha.unsqueeze(1), encoder_outputs).squeeze(1) # context_t: (batch_size, hidden_dim) \n",
    "        \n",
    "        out = self.output_layer(torch.cat([h_prev[0], context_t], 1))\n",
    "        \n",
    "        if self.copying: \n",
    "            probs = F.softmax(torch.cat([out, scores], 1), dim=1) # Appending scores over the input\n",
    "        else:\n",
    "            probs = F.softmax(out, dim=1)\n",
    "    \n",
    "        return probs, context_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2.2: Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can initialize and train the network:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "51\n",
      "Epoch = 0 | Loss = 57.10\n",
      "100\n",
      "51\n",
      "Epoch = 1 | Loss = 56.03\n",
      "100\n",
      "51\n",
      "Epoch = 2 | Loss = 56.21\n",
      "100\n",
      "51\n",
      "Epoch = 3 | Loss = 55.40\n",
      "100\n",
      "51\n",
      "Epoch = 4 | Loss = 54.28\n",
      "100\n",
      "51\n",
      "Epoch = 5 | Loss = 53.18\n",
      "100\n",
      "51\n",
      "Epoch = 6 | Loss = 53.46\n",
      "100\n",
      "51\n",
      "Epoch = 7 | Loss = 52.65\n",
      "100\n",
      "51\n",
      "Epoch = 8 | Loss = 52.51\n",
      "100\n",
      "51\n",
      "Epoch = 9 | Loss = 52.09\n",
      "100\n",
      "51\n",
      "Epoch = 10 | Loss = 49.58\n",
      "100\n",
      "51\n",
      "Epoch = 11 | Loss = 49.14\n",
      "100\n",
      "51\n",
      "Epoch = 12 | Loss = 48.22\n",
      "100\n",
      "51\n",
      "Epoch = 13 | Loss = 47.77\n",
      "100\n",
      "51\n",
      "Epoch = 14 | Loss = 46.48\n",
      "100\n",
      "51\n",
      "Epoch = 15 | Loss = 45.55\n",
      "100\n",
      "51\n",
      "Epoch = 16 | Loss = 43.88\n",
      "100\n",
      "51\n",
      "Epoch = 17 | Loss = 43.53\n",
      "100\n",
      "51\n",
      "Epoch = 18 | Loss = 42.03\n",
      "100\n",
      "51\n",
      "Epoch = 19 | Loss = 40.59\n",
      "100\n",
      "51\n",
      "Epoch = 20 | Loss = 40.77\n",
      "100\n",
      "51\n",
      "Epoch = 21 | Loss = 40.02\n",
      "100\n",
      "51\n",
      "Epoch = 22 | Loss = 38.97\n",
      "100\n",
      "51\n",
      "Epoch = 23 | Loss = 38.17\n",
      "100\n",
      "51\n",
      "Epoch = 24 | Loss = 37.23\n",
      "100\n",
      "51\n",
      "Epoch = 25 | Loss = 35.92\n",
      "100\n",
      "51\n",
      "Epoch = 26 | Loss = 36.26\n",
      "100\n",
      "51\n",
      "Epoch = 27 | Loss = 35.38\n",
      "100\n",
      "51\n",
      "Epoch = 28 | Loss = 34.72\n",
      "100\n",
      "51\n",
      "Epoch = 29 | Loss = 34.13\n",
      "100\n",
      "51\n",
      "Epoch = 30 | Loss = 34.09\n",
      "100\n",
      "51\n",
      "Epoch = 31 | Loss = 33.32\n",
      "100\n",
      "51\n",
      "Epoch = 32 | Loss = 32.68\n",
      "100\n",
      "51\n",
      "Epoch = 33 | Loss = 32.06\n",
      "100\n",
      "51\n",
      "Epoch = 34 | Loss = 31.53\n",
      "100\n",
      "51\n",
      "Epoch = 35 | Loss = 30.84\n",
      "100\n",
      "51\n",
      "Epoch = 36 | Loss = 30.30\n",
      "100\n",
      "51\n",
      "Epoch = 37 | Loss = 29.48\n",
      "100\n",
      "51\n",
      "Epoch = 38 | Loss = 28.83\n",
      "100\n",
      "51\n",
      "Epoch = 39 | Loss = 28.14\n",
      "100\n",
      "51\n",
      "Epoch = 40 | Loss = 27.47\n",
      "100\n",
      "51\n",
      "Epoch = 41 | Loss = 26.64\n",
      "100\n",
      "51\n",
      "Epoch = 42 | Loss = 25.63\n",
      "100\n",
      "51\n",
      "Epoch = 43 | Loss = 24.95\n",
      "100\n",
      "51\n",
      "Epoch = 44 | Loss = 24.63\n",
      "100\n",
      "51\n",
      "Epoch = 45 | Loss = 23.78\n",
      "100\n",
      "51\n",
      "Epoch = 46 | Loss = 22.87\n",
      "100\n",
      "51\n",
      "Epoch = 47 | Loss = 22.60\n",
      "100\n",
      "51\n",
      "Epoch = 48 | Loss = 21.92\n",
      "100\n",
      "51\n",
      "Epoch = 49 | Loss = 20.76\n",
      "100\n",
      "51\n",
      "Epoch = 50 | Loss = 20.50\n",
      "100\n",
      "51\n",
      "Epoch = 51 | Loss = 20.17\n",
      "100\n",
      "51\n",
      "Epoch = 52 | Loss = 19.49\n",
      "100\n",
      "51\n",
      "Epoch = 53 | Loss = 18.47\n",
      "100\n",
      "51\n",
      "Epoch = 54 | Loss = 18.26\n",
      "100\n",
      "51\n",
      "Epoch = 55 | Loss = 17.78\n",
      "100\n",
      "51\n",
      "Epoch = 56 | Loss = 17.37\n",
      "100\n",
      "51\n",
      "Epoch = 57 | Loss = 17.07\n",
      "100\n",
      "51\n",
      "Epoch = 58 | Loss = 16.44\n",
      "100\n",
      "51\n",
      "Epoch = 59 | Loss = 16.40\n",
      "100\n",
      "51\n",
      "Epoch = 60 | Loss = 16.11\n",
      "100\n",
      "51\n",
      "Epoch = 61 | Loss = 15.20\n",
      "100\n",
      "51\n",
      "Epoch = 62 | Loss = 15.20\n",
      "100\n",
      "51\n",
      "Epoch = 63 | Loss = 14.44\n",
      "100\n",
      "51\n",
      "Epoch = 64 | Loss = 14.27\n",
      "100\n",
      "51\n",
      "Epoch = 65 | Loss = 13.78\n",
      "100\n",
      "51\n",
      "Epoch = 66 | Loss = 13.74\n",
      "100\n",
      "51\n",
      "Epoch = 67 | Loss = 13.25\n",
      "100\n",
      "51\n",
      "Epoch = 68 | Loss = 12.55\n",
      "100\n",
      "51\n",
      "Epoch = 69 | Loss = 12.59\n",
      "100\n",
      "51\n",
      "Epoch = 70 | Loss = 12.19\n",
      "100\n",
      "51\n",
      "Epoch = 71 | Loss = 12.05\n",
      "100\n",
      "51\n",
      "Epoch = 72 | Loss = 11.87\n",
      "100\n",
      "51\n",
      "Epoch = 73 | Loss = 11.23\n",
      "100\n",
      "51\n",
      "Epoch = 74 | Loss = 11.30\n",
      "100\n",
      "51\n",
      "Epoch = 75 | Loss = 10.69\n",
      "100\n",
      "51\n",
      "Epoch = 76 | Loss = 10.58\n",
      "100\n",
      "51\n",
      "Epoch = 77 | Loss = 10.28\n",
      "100\n",
      "51\n",
      "Epoch = 78 | Loss = 10.16\n",
      "100\n",
      "51\n",
      "Epoch = 79 | Loss = 9.88\n",
      "100\n",
      "51\n",
      "Epoch = 80 | Loss = 9.90\n",
      "100\n",
      "51\n",
      "Epoch = 81 | Loss = 9.36\n",
      "100\n",
      "51\n",
      "Epoch = 82 | Loss = 9.13\n",
      "100\n",
      "51\n",
      "Epoch = 83 | Loss = 9.06\n",
      "100\n",
      "51\n",
      "Epoch = 84 | Loss = 8.98\n",
      "100\n",
      "51\n",
      "Epoch = 85 | Loss = 8.81\n",
      "100\n",
      "51\n",
      "Epoch = 86 | Loss = 8.25\n",
      "100\n",
      "51\n",
      "Epoch = 87 | Loss = 8.19\n",
      "100\n",
      "51\n",
      "Epoch = 88 | Loss = 7.87\n",
      "100\n",
      "51\n",
      "Epoch = 89 | Loss = 7.99\n",
      "100\n",
      "51\n",
      "Epoch = 90 | Loss = 7.71\n",
      "100\n",
      "51\n",
      "Epoch = 91 | Loss = 7.57\n",
      "100\n",
      "51\n",
      "Epoch = 92 | Loss = 7.38\n",
      "100\n",
      "51\n",
      "Epoch = 93 | Loss = 7.29\n",
      "100\n",
      "51\n",
      "Epoch = 94 | Loss = 7.18\n",
      "100\n",
      "51\n",
      "Epoch = 95 | Loss = 6.95\n",
      "100\n",
      "51\n",
      "Epoch = 96 | Loss = 6.83\n",
      "100\n",
      "51\n",
      "Epoch = 97 | Loss = 6.65\n",
      "100\n",
      "51\n",
      "Epoch = 98 | Loss = 6.51\n",
      "100\n",
      "51\n",
      "Epoch = 99 | Loss = 6.61\n"
     ]
    }
   ],
   "source": [
    "def train(ex, model, optim):\n",
    "    model.train()\n",
    "    \n",
    "    x, x_lens, x_mask, y, y_mask, y_in_x_inds = ex\n",
    "    \n",
    "    # Variable(x.cuda()) if using GPU\n",
    "    x, x_lens, x_mask, y, y_mask, y_in_x_inds = Variable(x), Variable(x_lens), Variable(x_mask), Variable(y), Variable(y_mask), Variable(y_in_x_inds)\n",
    "    \n",
    "    encoder_outputs = model.encode(x) # (batch_size, seq_len, hidden_dim*2)\n",
    "    encoder_proj_outputs = model.enc_to_dec(encoder_outputs) # (batch_size, seq_len, hidden_dim)\n",
    "    \n",
    "    ###CHANGE: make use of x_lens to index the last hidden states\n",
    "    batch_size = x.size(0)\n",
    "    seq_len = x.size(1)\n",
    "    h_0 = torch.index_select(encoder_proj_outputs.view(batch_size*seq_len,-1),0,x_lens) # be careful when input sequences have paddings\n",
    "    \n",
    "    c_0 = Variable(torch.zeros(h_0.size(0), h_0.size(1)).zero_()) \n",
    "    hidden = (h_0, c_0)\n",
    "    \n",
    "    p_y_seq = []\n",
    "    for i in range(y.size(1)):\n",
    "        #output = model.decode(hidden) \n",
    "        #y_emb = model.out_embedding(y[:, i]) # y_emb: (batch_size, embedding_dim)        \n",
    "        #hidden = model.decoder(y_emb, hidden) # (h_t, c_t): (batch_size, hidden_dim)\n",
    "        \n",
    "        ###CHANGE: update the decode function, move the code that uses y[:, i] down\n",
    "        output, context_t = model.decode(encoder_outputs, encoder_proj_outputs, x_mask, hidden) # with attention\n",
    "        \n",
    "        ###compute the next hidden state using the current output y[:, i]\n",
    "        y_emb = model.out_embedding(y[:, i]) # y_emb: (batch_size, embedding_dim)\n",
    "        hidden = model.decoder(torch.cat([y_emb, context_t], 1), hidden) \n",
    "        \n",
    "        p_y_t = output.gather(1, y[:, i].unsqueeze(1)) # (batch_size, 1)\n",
    "        \n",
    "        if model.copying:\n",
    "            copy_dist = output[:, model.out_vocab_size:model.out_vocab_size + y_in_x_inds.size(2)] # (batch_size, input_len)\n",
    "            # (batch_size, 1, input_len), (batch_size, input_len, 1)\n",
    "            copying_p_y_t = torch.bmm(copy_dist.unsqueeze(1), y_in_x_inds[:, i].unsqueeze(2)).squeeze(2)\n",
    "            p_y_t = p_y_t + copying_p_y_t\n",
    "                \n",
    "        p_y_seq.append(p_y_t)\n",
    "\n",
    "    p_y_seq = torch.cat([_ for _ in p_y_seq], 1) # (batch_size, seq_len)\n",
    "    p_y_seq = torch.masked_select(p_y_seq, y_mask)\n",
    "    loss = -torch.sum(torch.log(p_y_seq))/y.size(0) # loss = -\\sum_i log p(y|x)\n",
    "\n",
    "    # Clear gradients and run backward\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients, max_norm * v/||v|| if ||v|| > max_norm\n",
    "    torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=10.0)\n",
    "\n",
    "    # Update parameters\n",
    "    optim.step()\n",
    "    \n",
    "    return loss.data[0]\n",
    "\n",
    "#model = Seq2Seq(50, 20, input_vocab, output_vocab)\n",
    "model = AttentionSeq2Seq(50, 20, input_vocab, output_vocab, True)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "# training loop\n",
    "n_epochs = 100\n",
    "for e in range(n_epochs):\n",
    "    train_loss = 0.0\n",
    "    for ex in train_loader:\n",
    "        l = train(ex, model, optim)\n",
    "        train_loss += l\n",
    "    print(\"Epoch = %d | Loss = %.2f\" % (e, train_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2.3: Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model, similar to training. Using greedy search to infer the most likely sequence output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Gold:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ]\n",
      "Gold:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ]\n",
      "Gold:  predict( mod , 12 ) <end>\n",
      "Predict:  predict( mod , 12 ) <end> <end> , 12 ) <end> <end> , 12 )\n",
      "Gold:  min( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  max( WeatherHistory [ 'Temperature' ] ) <end> <end> 'Temperature' ] ) <end> <end> <end> )\n",
      "Gold:  min( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  max( WeatherHistory [ 'Temperature' ] ) <end> <end> 'Temperature' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  mean( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  mean( WeatherHistory [ 'Temperature' ] ) <end> <end> 'Temperature' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end>\n",
      "Predict:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ]\n",
      "Gold:  max( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  <end> ) <end> <end> <end> ) <end> <end> <end> ) <end> <end> <end> ) <end>\n",
      "Gold:  predict( mod , 12 ) <end>\n",
      "Predict:  predict( mod , 12 ) <end> <end> , 12 ) <end> <end> , 12 )\n",
      "Gold:  predict( mod , 12 ) <end>\n",
      "Predict:  predict( mod , WeatherHistory [ 'Temperature' ] ) <end> <end> <end> , WeatherHistory [ 'Temperature'\n",
      "Gold:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  lm( WeatherHistory [ 'Humidity' ] ) <end> <end> , WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Gold:  mean( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  mean( WeatherHistory [ 'Temperature' ] ) <end> <end> 'Temperature' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  max( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  max( WeatherHistory [ 'Temperature' ] ) <end> <end> 'Temperature' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  mean( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  mean( WeatherHistory [ 'Temperature' ] ) <end> <end> 'Temperature' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  min( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  mean( WeatherHistory [ 'Temperature' ] ) <end> <end> 'Temperature' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  predict( mod , 12 ) <end>\n",
      "Predict:  predict( mod , 12 ) <end> <end> , 12 ) <end> <end> , WeatherHistory [\n",
      "Gold:  mean( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  max( WeatherHistory [ 'Temperature' ] ) <end> <end> 'Temperature' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  predict( mod , 12 ) <end>\n",
      "Predict:  predict( mod , 12 ) <end> <end> , 12 ) <end> <end> <end> , 12\n",
      "Gold:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ]\n",
      "Gold:  min( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  max( WeatherHistory [ 'Temperature' ] ) <end> <end> 'Temperature' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end>\n",
      "Predict:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Gold:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end>\n",
      "Predict:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ]\n",
      "Gold:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end>\n",
      "Predict:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ]\n",
      "Gold:  max( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  mean( WeatherHistory [ 'Temperature' ] ) <end> <end> 'Temperature' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end>\n",
      "Predict:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end> <end> <end> 'FellingTemperature'\n",
      "Gold:  min( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  mean( WeatherHistory [ 'Temperature' ] ) <end> <end> 'Temperature' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  mean( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  mean( WeatherHistory [ 'Temperature' ] ) <end> <end> 'Temperature' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end>\n",
      "Predict:  <end> WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ]\n",
      "Gold:  max( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  max( WeatherHistory [ 'Temperature' ] ) <end> <end> 'Temperature' ] ) <end> <end> <end> )\n",
      "Gold:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ]\n",
      "Gold:  min( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  max( WeatherHistory [ 'Temperature' ] ) <end> <end> 'Temperature' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  predict( mod , 12 ) <end>\n",
      "Predict:  predict( mod , 12 ) <end> <end> , 12 ) <end> <end> , 12 )\n",
      "Gold:  min( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  mean( WeatherHistory [ 'Temperature' ] ) <end> <end> 'Temperature' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ]\n",
      "Gold:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ]\n",
      "Gold:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ]\n",
      "Gold:  max( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  mean( WeatherHistory [ 'Temperature' ] ) <end> <end> 'Temperature' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ]\n",
      "Gold:  min( WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  <end> 'Temperature' ] , WeatherHistory [ 'Temperature' ] ) <end> <end> <end> , WeatherHistory [\n",
      "Test accuracy: 0.3076923076923077\n"
     ]
    }
   ],
   "source": [
    "def test_batch(data_loader, model, max_len=15):\n",
    "    model.eval()\n",
    "    \n",
    "    num_correct = 0\n",
    "    for ex in data_loader:\n",
    "        x, x_lens, x_mask, y, y_mask, y_in_x_inds = ex \n",
    "        \n",
    "        x, x_lens, x_mask = Variable(x), Variable(x_lens), Variable(x_mask)\n",
    "    \n",
    "        encoder_outputs = model.encode(x) # (batch_size, seq_len, hidden_dim*2)\n",
    "        encoder_proj_outputs = model.enc_to_dec(encoder_outputs) # (batch_size, seq_len, hidden_dim)\n",
    "        \n",
    "        ###CHANGE: make use of x_lens to index the last hidden states\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = x.size(1)\n",
    "        h_0 = torch.index_select(encoder_proj_outputs.view(batch_size*seq_len,-1),0,x_lens) # be careful when input sequences have paddings\n",
    "    \n",
    "        c_0 = Variable(torch.zeros(h_0.size(0), h_0.size(1)).zero_()) \n",
    "        hidden = (h_0, c_0)\n",
    "        \n",
    "        ###CHANGE: start with empty prediction\n",
    "        seq = []\n",
    "        for i in range(max_len):\n",
    "            #output = model.decode(hidden) \n",
    "            \n",
    "            ###CHANGE: update the decode function, move the code that uses y[:, i] down\n",
    "            output, context_t = model.decode(encoder_outputs, encoder_proj_outputs, x_mask, hidden) # with attention\n",
    "        \n",
    "            sampleLogprobs, it = torch.max(output.data, 1)\n",
    "            y_t = it.view(-1).long()\n",
    "            seq.append(y_t)\n",
    "            \n",
    "            if model.copying:\n",
    "                new_y_t = []\n",
    "                for j in range(y_t.size(0)):\n",
    "                    if y_t[j] < model.out_vocab_size:\n",
    "                        new_y_t.append(y_t[j])\n",
    "                    else:\n",
    "                        k = x.data[j, y_t[j]-model.out_vocab_size]\n",
    "                        w = model.input_vocab.get_word(k)\n",
    "                        new_k = model.output_vocab.get_index(w)\n",
    "                        new_y_t.append(new_k)\n",
    "                y_t = torch.LongTensor(new_y_t)\n",
    "            \n",
    "            ###compute the next hidden state using the current output y_t\n",
    "            y_prev = Variable(y_t)\n",
    "            y_emb = model.out_embedding(y_prev) # y_emb: (batch_size, embedding_dim)\n",
    "            hidden = model.decoder(torch.cat([y_emb, context_t], 1), hidden) \n",
    "            \n",
    "            #hidden = model.decoder(y_emb, hidden)\n",
    "        \n",
    "        pred_y = torch.cat([_.unsqueeze(1) for _ in seq], 1)\n",
    "        \n",
    "        for idx in range(batch_size):\n",
    "            gold_toks = []\n",
    "            for wi in y[idx].tolist():\n",
    "                gold_toks.append(model.output_vocab.get_word(wi))\n",
    "            print(\"Gold: \", ' '.join(gold_toks))\n",
    "        \n",
    "            pred_toks = []\n",
    "            for wi in pred_y[idx].tolist():\n",
    "                #w = model.output_vocab.get_word(wi)\n",
    "            \n",
    "                if wi < model.out_vocab_size:\n",
    "                    w = model.output_vocab.get_word(wi)\n",
    "                else:\n",
    "                    w = model.input_vocab.get_word(x.data[idx][wi-model.out_vocab_size])\n",
    "                    #print(\"copying \", w)\n",
    "                    \n",
    "                pred_toks.append(w)\n",
    "                \n",
    "            print(\"Predict: \",' '.join(pred_toks))\n",
    "            \n",
    "            for i in range(len(gold_toks)):\n",
    "                g_tok = gold_toks[i]\n",
    "                p_tok = pred_toks[i]\n",
    "                if (g_tok != p_tok):\n",
    "                    break\n",
    "                elif (g_tok == \"<end>\"):\n",
    "                    num_correct += 1\n",
    "                    \n",
    "                    \n",
    "    print(\"Test accuracy: {}\".format(num_correct / len(data_loader)))\n",
    "                \n",
    "        \n",
    "test_batch(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
