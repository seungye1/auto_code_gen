{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[1]:\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "torch.manual_seed(1013)\n",
    "\n",
    "\n",
    "# # Data Preparation\n",
    "\n",
    "# ## Data Cleaning\n",
    "#\n",
    "# * Spacing for punctuation\n",
    "# * Split train and test data\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/codegen_small.csv\")\n",
    "data_x = df[\"utterance\"]\n",
    "data_y = df[\"target\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.2)\n",
    "\n",
    "Datasets = {\n",
    "    # [cont, cont, cont, cont]\n",
    "    \"iris\" : [(\"sepal_length\", \"c\"), (\"sepal_width\", \"c\"),  (\"petal_length\", \"c\"), (\"petal_width\", \"c\")],\n",
    "    # [cont, dis, cont, dis, cont, dis, dis, dis, dis, dis, dis, cont, cont, cont, dis]\n",
    "    \"adult\" : [(\"age\", \"c\"), (\"workclass\", \"d\"), (\"fnlwgt\", \"c\"), (\"education\", \"d\"), (\"education_num\", \"c\"),  (\"marital_status\", \"d\"), (\"occupation\", \"d\"), (\"house_serv\", \"d\"), (\"relationship\", \"d\"), (\"race\", \"d\"), (\"sex\", \"d\"), (\"capital_gain\", \"c\"), (\"capital_loss\", \"c\"), (\"hours_per_week\", \"d\"), (\"native_country\", \"d\")],\n",
    "    # [dis, rest are cont]\n",
    "    \"wine\" : [(\"alcohol\", \"d\"), (\"malic_acid\", \"c\"), (\"ash\", \"c\"), (\"alcalinity_of_ash\", \"c\"), (\"magnesium\", \"c\"), (\"total_phenols\", \"c\"),(\"flavanoids\", \"c\"), (\"nonflavanoid_phenols\", \"c\"), (\"proanthocyanins\", \"c\"), (\"varor_intensity\", \"c\"), (\"hue\", \"c\")],\n",
    "    # all dis\n",
    "    \"car\" : [(\"buying\", \"c\"), (\"maint\", \"c\"), (\"comfort\", \"c\"), (\"doors\", \"c\"), (\"persons\", \"c\"), (\"lug_boot\", \"c\"), (\"safety\", \"c\")],\n",
    "    # all cont\n",
    "    \"breast_cancer\" : [(\"radius\", \"c\"), (\"texture\", \"c\"), (\"perimeter\", \"c\"), (\"area\", \"c\"), (\"smoothness\", \"c\"), (\"compactness\", \"c\"), (\"concavity\", \"c\"), (\"concave_points\", \"c\"), (\"symmetry\", \"c\"), (\"fractal_dimension\", \"c\")],\n",
    "    # [dis, dis, dis, cont, cont, dis, dis, cont, dis]\n",
    "    \"heart_disease\" : [(\"age\", \"d\"), (\"sex\", \"d\"), (\"cp\", \"d\"), (\"trestbps\", \"c\"), (\"chol\", \"c\"), (\"fbs\", \"d\"), (\"restecg\", \"d\"), (\"thalach\", \"c\"), (\"num\", \"d\")],\n",
    "    # all con except for the last one (quality)\n",
    "    \"wine_quality\" : [(\"fixed_acidity\", \"c\"), (\"volatile_acidity\", \"c\"), (\"citric_acid\", \"c\"), (\"residual_sugar\", \"c\"), (\"chlorides\", \"c\"), (\"free_sulfur_dioxide\", \"c\"), (\"total_sulfur_dioxide\", \"c\"), (\"density\", \"c\"), (\"pH\", \"c\"), (\"sulphates\", \"c\"), (\"alcohol\", \"c\"), (\"quality\", \"d\")],\n",
    "    # [cont, cont, cont, dis, dis]\n",
    "    \"smartphones\" : [(\"triaxial_acceleration\", \"c\"), (\"triaxial_angular_velocity\", \"c\"), (\"561_feature\", \"c\"), (\"label\", \"d\"), (\"identifier\", \"d\")],\n",
    "    # [dis, dis, dis, dis, cont, cont, cont, cont, cont, cont, cont, cont, cont]\n",
    "    \"forest_fire\" : [(\"x\", \"d\"), (\"y\", \"d\"), (\"month\", \"d\"), (\"day\", \"d\"), (\"FFMC\", \"c\"), (\"DMC\", \"c\"), (\"DC\", \"c\"), (\"ISI\", \"c\"), (\"temp\", \"c\"), (\"RH\", \"c\"), (\"wind\", \"c\"), (\"rain\", \"c\"), (\"area\", \"c\")],\n",
    "    # [dis, cont, cont, cont, cont, cont, cont, cont]\n",
    "    \"abalone\" : [(\"sex\", \"d\"), (\"length\", \"c\"), (\"diameter\", \"c\"), (\"height\", \"c\"), (\"whole_weight\", \"c\"), (\"shucked_weight\", \"c\"), (\"viscera\", \"c\"), (\"shell_weight\", \"c\")],\n",
    "    # [dis, dis, dis, dis, dis, dis, dis, dis, dis, dis, cont, cont, cont, cont, dis, cont, cont, cont, cont, cont]\n",
    "    \"bank_marketing\" : [(\"age\", \"d\"), (\"job\", \"d\"), (\"marital\", \"d\"), (\"education\", \"d\"), (\"default\", \"d\"), (\"housing\", \"d\"), (\"loan\", \"d\"), (\"contact\", \"d\"), (\"month\", \"d\"), (\"day_of_week\", \"d\"), (\"duration\", \"c\"), (\"campaign\", \"c\"), (\"pdays\", \"c\"), (\"previous\", \"c\"), (\"poutcome\", \"d\"), (\"emp.var.rate\", \"c\"), (\"cons.price.idx\", \"c\"), (\"cons.conf.idx\", \"c\"), (\"euribor3m\", \"c\"), (\"nr.employed\", \"c\")]\n",
    "}\n",
    "\n",
    "data_cols = list(Datasets.keys())\n",
    "\n",
    "for list_col in Datasets.values():\n",
    "    for col in list_col:\n",
    "        data_cols.append(col[0])\n",
    "\n",
    "\n",
    "# ## Building Vocabulary\n",
    "# * Input Vocab: `input_vocab`\n",
    "# * Output Vocab: `output_vocab`\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "class Vocabulary():\n",
    "    END_OF_SENTENCE = '<end>'\n",
    "    NULL = 'NULL'\n",
    "    UNKNOWN = 'UNK'\n",
    "    END_OF_SENTENCE_INDEX = 2\n",
    "    def __init__(self, i):\n",
    "        self.tok2ind = {self.NULL: 0, self.UNKNOWN: 1, self.END_OF_SENTENCE: 2}\n",
    "        self.ind2tok = {0: self.NULL, 1: self.UNKNOWN, 2: self.END_OF_SENTENCE}\n",
    "        self.i = i\n",
    "\n",
    "    def add(self, token):\n",
    "        if token not in self.tok2ind:\n",
    "            index = self.i\n",
    "            self.tok2ind[token] = index\n",
    "            self.ind2tok[index] = token\n",
    "            self.i += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tok2ind)\n",
    "\n",
    "    def get_index(self, word):\n",
    "        if word in self.tok2ind:\n",
    "            return self.tok2ind[word]\n",
    "        return self.tok2ind[self.UNKNOWN]\n",
    "\n",
    "    def get_word(self, i):\n",
    "        return self.ind2tok[i]\n",
    "\n",
    "    def sentence_to_indices(self, sentence):\n",
    "        words = [x for x in sentence.split(' ')]\n",
    "        words.append(self.END_OF_SENTENCE)\n",
    "        indices = [self.get_index(w) for w in words]\n",
    "        return indices\n",
    "\n",
    "def is_not_numeric(s):\n",
    "    try:\n",
    "        val = float(s)\n",
    "        return False\n",
    "    except:\n",
    "        return True\n",
    "\n",
    "def build_vocab(examples):\n",
    "    word_counts = Counter()\n",
    "    for ex in examples:\n",
    "        words = [w for w in ex.split(' ') if w.strip()]\n",
    "        word_counts.update(words)\n",
    "    word_list = [w for w in word_counts if w not in data_cols and is_not_numeric(w)]\n",
    "    word_vocab = Vocabulary(3)\n",
    "    for w in word_list:\n",
    "        word_vocab.add(w)\n",
    "    return word_vocab\n",
    "\n",
    "def build_oov(x_exs, input_vocab_words, i):\n",
    "    word_dict = Vocabulary(i)\n",
    "    for ex in x_exs:\n",
    "        words = [w for w in ex.split(' ') if w.strip()]\n",
    "\n",
    "        for w in words:\n",
    "            if w not in input_vocab_words:\n",
    "                word_dict.add(w)\n",
    "    fns = ['mean', 'std', 'maximum', 'minimum', 'ranges', 'summation',\n",
    "        'std', 'variance', 'quantile', 'corr', 'histogram',\n",
    "        'boxplot', 'load', 'describe', 'quantile', 'scatterplot', 'corr', 'lr',\n",
    "        'predict', 'less', 'equal', 'greater']\n",
    "    for fn in fns:\n",
    "        word_dict.add(fn)\n",
    "    return word_dict\n",
    "\n",
    "input_vocab = build_vocab(train_x)\n",
    "output_vocab = build_vocab(train_y)\n",
    "oov_vocab = build_oov(test_x, input_vocab.tok2ind.keys(), len(output_vocab.tok2ind.keys()))\n",
    "\n",
    "\n",
    "# ## Process train and test datasets as Examples\n",
    "#\n",
    "# * Create Example class for each ex\n",
    "# * Prepare to load to PyTorch dataloader by making specific Dataset class\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import string\n",
    "\n",
    "class Example():\n",
    "    def __init__(self, x_str, y_str, input_vocab, output_vocab, oov_vocab):\n",
    "        self.x_str = x_str\n",
    "        self.y_str = y_str\n",
    "        self.x_toks = x_str.split(' ')\n",
    "        self.y_toks = y_str.split(' ')\n",
    "        self.input_vocab = input_vocab\n",
    "        self.output_vocab = output_vocab\n",
    "        self.oov_vocab = oov_vocab\n",
    "        self.x_ind = torch.LongTensor(input_vocab.sentence_to_indices(x_str))\n",
    "        self.y_ind = torch.LongTensor(output_vocab.sentence_to_indices(y_str))\n",
    "        self.oov_ind_x = torch.LongTensor(oov_vocab.sentence_to_indices(x_str))\n",
    "        self.oov_ind_y = torch.LongTensor(oov_vocab.sentence_to_indices(y_str))\n",
    "\n",
    "        # 1: batch, row: the y pos, col: the x pos\n",
    "        self.y_in_x_ind = torch.FloatTensor(([[int(x_tok == y_tok) for x_tok in self.x_toks] for y_tok in self.y_toks]))\n",
    "\n",
    "class StatCodeDataset(Dataset):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.examples[index]\n",
    "\n",
    "train_exs = []\n",
    "for x, y in zip(train_x, train_y):\n",
    "    train_exs.append(Example(x, y, input_vocab, output_vocab, oov_vocab))\n",
    "train_dataset = StatCodeDataset(train_exs)\n",
    "\n",
    "test_exs = []\n",
    "for x, y in zip(test_x, test_y):\n",
    "    test_exs.append(Example(x, y, input_vocab, output_vocab, oov_vocab))\n",
    "test_dataset = StatCodeDataset(test_exs)\n",
    "\n",
    "\n",
    "# ## Vectorizing Examples\n",
    "#\n",
    "# * Write vectorizing function for PyTorch DataLoader\n",
    "# * Load data into dataloader\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "def vectorize(batch):\n",
    "    # all vectors size (batch, max_input_len or max_output_len)\n",
    "    max_input_len = max([ex.x_ind.size(0) for ex in batch])\n",
    "    max_output_len = max([ex.y_ind.size(0) for ex in batch])\n",
    "\n",
    "    # input & output seq (init = 0)\n",
    "    # batch number rows, max of word sequence number cols\n",
    "    x = torch.LongTensor(len(batch), max_input_len).zero_()\n",
    "    y = torch.LongTensor(len(batch), max_output_len).zero_()\n",
    "    oov_x = torch.LongTensor(len(batch), max_input_len).zero_()\n",
    "    oov_y = torch.LongTensor(len(batch), max_output_len).zero_()\n",
    "\n",
    "    # softmax mask for input, masked_select for output\n",
    "    # batch number rows, max of word seq number cols\n",
    "    x_mask = torch.ByteTensor(len(batch), max_input_len).fill_(1)\n",
    "    y_mask = torch.ByteTensor(len(batch), max_output_len).zero_()\n",
    "\n",
    "    # stores the last index of each sequence\n",
    "    x_lens = torch.LongTensor(len(batch)).zero_()\n",
    "\n",
    "    # y_in_x_index resized to max\n",
    "    y_in_x_ind = torch.FloatTensor(len(batch), max_output_len, max_input_len).zero_()\n",
    "\n",
    "    for i, ex in enumerate(batch):\n",
    "        # edit ith row from x & y and fill with x_inds & y_inds\n",
    "        x[i, :ex.x_ind.size(0)].copy_(ex.x_ind)\n",
    "        oov_x[i, :ex.x_ind.size(0)].copy_(ex.oov_ind_x)\n",
    "        y[i, :ex.y_ind.size(0)].copy_(ex.y_ind)\n",
    "        oov_y[i, :ex.y_ind.size(0)].copy_(ex.oov_ind_y)\n",
    "\n",
    "        # i*max_input_len for getting last hidden state from 2d tensor\n",
    "        # (batch_size*max_len, embedding dim)\n",
    "        # also has last index of each seq\n",
    "        x_lens[i] = i*max_input_len + ex.x_ind.size(0)-1\n",
    "\n",
    "        # mask values to zero for input and to one for output\n",
    "        x_mask[i, :ex.x_ind.size(0)].fill_(0)\n",
    "        y_mask[i, :ex.y_ind.size(0)].fill_(1)\n",
    "\n",
    "        # copying 1 or no\n",
    "        y_in_x_ind[i, :ex.y_in_x_ind.size(0), :ex.y_in_x_ind.size(1)].copy_(ex.y_in_x_ind)\n",
    "\n",
    "\n",
    "    return x, x_lens, x_mask, y, y_mask, y_in_x_ind, oov_x, oov_y\n",
    "\n",
    "train_sampler = torch.utils.data.sampler.RandomSampler(train_dataset)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=50,\n",
    "    sampler=train_sampler,\n",
    "    num_workers=30,\n",
    "    collate_fn=vectorize\n",
    ")\n",
    "\n",
    "test_sampler = torch.utils.data.sampler.SequentialSampler(test_dataset)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=10,\n",
    "    sampler=test_sampler,\n",
    "    num_workers=1,\n",
    "    collate_fn=vectorize\n",
    ")\n",
    "max_input_len = max([ex.x_ind.size(0) for ex in test_dataset])\n",
    "\n",
    "\n",
    "# # Building the Model\n",
    "\n",
    "# ## LSTM\n",
    "# * stack bi-directional LSTM\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "class StackBRNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers=1):\n",
    "        super(StackBRNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.rnns = nn.ModuleList()\n",
    "\n",
    "        # have input_seq and out_seq length of LSTM Stacked\n",
    "        for i in range(num_layers):\n",
    "            input_dim = input_dim if i == 0 else hidden_dim * 2\n",
    "            self.rnns.append(nn.LSTM(input_dim, hidden_dim, bidirectional=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (seq_len, batch_size, input_dim)\n",
    "        # use inputs as last hidden_layer output\n",
    "        x = x.transpose(0, 1)\n",
    "        outputs = [x]\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            rnn_input = outputs[-1]\n",
    "            rnn_output = self.rnns[i](rnn_input)[0]\n",
    "            outputs.append(rnn_output)\n",
    "\n",
    "        # transpose back to (batch_size, seq_len, 2*hidden_dim aka output dim)\n",
    "        h_output = outputs[-1]\n",
    "        h_output = h_output.transpose(0, 1)\n",
    "        return h_output\n",
    "\n",
    "\n",
    "# ## Attention Sequence to Sequence Model With Copying\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "class AttentionSeq2Seq(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, input_vocab, output_vocab):\n",
    "        super(AttentionSeq2Seq, self).__init__()\n",
    "        self.input_vocab = input_vocab\n",
    "        self.output_vocab = output_vocab\n",
    "        self.in_vocab_size = len(self.input_vocab)\n",
    "        self.out_vocab_size = len(self.output_vocab)\n",
    "\n",
    "        self.in_embedding = nn.Embedding(self.in_vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.out_embedding = nn.Embedding(self.out_vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        self.encoder = StackBRNN(embedding_dim, hidden_dim)\n",
    "        self.decoder = nn.LSTMCell(embedding_dim + hidden_dim*2, hidden_dim)\n",
    "\n",
    "        self.enc_to_dec = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        self.output_layer = nn.Linear(hidden_dim + hidden_dim*2, self.out_vocab_size)\n",
    "\n",
    "    def encode(self, x):\n",
    "        # batch_size, seq_len, embedding_dim\n",
    "        x_emb = self.in_embedding(x)\n",
    "        # batch_size, seq_len, hidden_dim*2 (bc StackBRNN does hidden_dim*2)\n",
    "        output = self.encoder(x_emb)\n",
    "        return output\n",
    "\n",
    "    def decode(self, encoder_outputs, encoder_proj_outputs, x_mask, h_prev):\n",
    "        # copy scores: (batch_size, seq_len)\n",
    "        # scores calculated using hidden state\n",
    "        # encoder outputs, previous hidden outputs\n",
    "        # (batch_size, seq_len, hidden_dim) * (batch_size, hidden_dim, 1)\n",
    "        scores = torch.bmm(encoder_proj_outputs, h_prev[0].unsqueeze(2)).squeeze(2)\n",
    "        scores.data.masked_fill_(x_mask.data, -float('inf'))\n",
    "        alpha = F.softmax(scores, dim=1)\n",
    "        # context at t: (batch_size, CONTEXT_VAL 1, seq_len)\n",
    "        # (batch_size, 1, seq_len) * (batch_size, seq_len, hidden_dim)\n",
    "        context_t = torch.bmm(alpha.unsqueeze(1), encoder_outputs).squeeze(1)\n",
    "        # generate scores (regular RNN)\n",
    "        # H_PREV: previous layer\n",
    "        out = self.output_layer(torch.cat([h_prev[0], context_t], 1))\n",
    "        probs = F.softmax(torch.cat([out, scores], 1), dim=1)\n",
    "        return probs, context_t\n",
    "\n",
    "# model = AttentionSeq2Seq(50, 20, input_vocab, output_vocab)\n",
    "model = torch.load(\"model/small_after_data_aug.model\")\n",
    "\n",
    "\n",
    "#  ## Train the model\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "def train(ex, model, optim):\n",
    "    # train mode\n",
    "    model.train()\n",
    "\n",
    "    x, x_lens, x_mask, y, y_mask, y_in_x_ind, oov_x, oov_y = ex\n",
    "    x, x_lens, x_mask, y, y_mask, y_in_x_ind = Variable(x), Variable(x_lens), Variable(x_mask), Variable(y), Variable(y_mask), Variable(y_in_x_ind)\n",
    "# print('x',x,'y', y, 'oovx', oov_x, 'oovy',oov_y)\n",
    "    # input: batch_size, seq_len\n",
    "    # output: batch_size, (seq_len, hidden_dim*2)\n",
    "    encoder_outputs = model.encode(x)\n",
    "\n",
    "    # input: batch_size, (seq_len, hidden_dim*2)\n",
    "    # output: batch_size, seq_len, hidden_dim\n",
    "    encoder_proj_outputs = model.enc_to_dec(encoder_outputs)\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "    seq_len = x.size(1)\n",
    "\n",
    "    # batch_1, seq_1: (hidden_dim, hidden_dim, ...., hidden_dim)\n",
    "    # batch_n, seq_t\n",
    "    # view encoder_proj_outputs as one long vector, select last hidden state output\n",
    "    h_0 = torch.index_select(encoder_proj_outputs.view(batch_size*seq_len, -1), 0, x_lens) # be careful when input sequences have paddings\n",
    "    c_0 = Variable(torch.zeros(h_0.size(0), h_0.size(1)).zero_())\n",
    "    hidden = (h_0, c_0)\n",
    "    prob_y_seq = []\n",
    "    for i in range(y.size(1)):\n",
    "        output, context_t = model.decode(encoder_outputs, encoder_proj_outputs, x_mask, hidden)\n",
    "\n",
    "        # next hidden state using current output location\n",
    "        # (embedding dim + hidden * 2, hidden)\n",
    "        y_emb = model.out_embedding(y[:, i])\n",
    "        hidden = model.decoder(torch.cat([y_emb, context_t], 1), hidden)\n",
    "\n",
    "        # prob @ time i\n",
    "        # (batch_size, 1)\n",
    "#         print(\"output\", output)\n",
    "#         print('y', y[:,i])\n",
    "        p_y_t = output.gather(1, y[:, i].unsqueeze(1)) # (batch_size, 1)\n",
    "#         print('y_t', i, p_y_t)        # (batch_size, input_len)\n",
    "        copy_dist = output[:, model.out_vocab_size:model.out_vocab_size + y_in_x_ind.size(2)]\n",
    "#         print('dist', copy_dist)\n",
    "#         print('y_inx', y_in_x_ind[:,i])\n",
    "        copy_p_y_t = torch.bmm(copy_dist.unsqueeze(1), y_in_x_ind[:, i].unsqueeze(2)).squeeze(2)\n",
    "#         print('copypyt', copy_p_y_t)\n",
    "\n",
    "        p_y_t = p_y_t + copy_p_y_t\n",
    "#         print('newo',p_y_t)\n",
    "        prob_y_seq.append(p_y_t)\n",
    "    prob_y_seq = torch.cat([_ for _ in prob_y_seq], 1)\n",
    "    prob_y_seq = torch.masked_select(prob_y_seq, y_mask)\n",
    "    loss = -torch.sum(torch.log(prob_y_seq))/y.size(0)\n",
    "\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    return loss.data[0]\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "n_epochs = 100\n",
    "for e in range(n_epochs):\n",
    "    train_loss = 0.0\n",
    "    for ex in train_loader:\n",
    "        l = train(ex, model, optim)\n",
    "        train_loss += l\n",
    "    print(\"Epoch = %d | Loss = %.2f\" % (e, train_loss))\n",
    "\n",
    "\n",
    "# ## Test batch\n",
    "\n",
    "# In[102]:\n",
    "\n",
    "\n",
    "def test_batch(data_loader, oov_vocab, model, max_len=15):\n",
    "    model.eval()\n",
    "\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    for ex in data_loader:\n",
    "        x, x_lens, x_mask, y, y_mask, y_in_x_inds, oov_x, oov_y = ex\n",
    "\n",
    "        x, x_lens, x_mask = Variable(x), Variable(x_lens), Variable(x_mask)\n",
    "\n",
    "        encoder_outputs = model.encode(x) # (batch_size, seq_len, hidden_dim*2)\n",
    "        encoder_proj_outputs = model.enc_to_dec(encoder_outputs) # (batch_size, seq_len, hidden_dim)\n",
    "\n",
    "        ###CHANGE: make use of x_lens to index the last hidden states\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = x.size(1)\n",
    "        h_0 = torch.index_select(encoder_proj_outputs.view(batch_size*seq_len,-1),0,x_lens) # be careful when input sequences have paddings\n",
    "\n",
    "        c_0 = Variable(torch.zeros(h_0.size(0), h_0.size(1)).zero_())\n",
    "        hidden = (h_0, c_0)\n",
    "\n",
    "        ###CHANGE: start with empty prediction\n",
    "        seq = []\n",
    "        for i in range(max_len):\n",
    "            #output = model.decode(hidden)\n",
    "\n",
    "            ###CHANGE: update the decode function, move the code that uses y[:, i] down\n",
    "            output, context_t = model.decode(encoder_outputs, encoder_proj_outputs, x_mask, hidden) # with attention\n",
    "\n",
    "            sampleLogprobs, it = torch.max(output.data, 1)\n",
    "            y_t = it.view(-1).long()\n",
    "            seq.append(y_t)\n",
    "\n",
    "            new_y_t = []\n",
    "            for j in range(y_t.size(0)):\n",
    "                if y_t[j] < model.out_vocab_size:\n",
    "                    w = y_t[j]\n",
    "                else:\n",
    "                    w = 1\n",
    "                new_y_t.append(w)\n",
    "\n",
    "            new_y_t = torch.LongTensor(new_y_t)\n",
    "\n",
    "            ###compute the next hidden state using the current output y_t\n",
    "            y_prev = Variable(new_y_t)\n",
    "            y_emb = model.out_embedding(y_prev) # y_emb: (batch_size, embedding_dim)\n",
    "            hidden = model.decoder(torch.cat([y_emb, context_t], 1), hidden)\n",
    "\n",
    "            #hidden = model.decoder(y_emb, hidden)\n",
    "\n",
    "        pred_y = torch.cat([_.unsqueeze(1) for _ in seq], 1)\n",
    "        for idx in range(batch_size):\n",
    "            gold_toks = []\n",
    "            y_list = y[idx].tolist()\n",
    "            oov_list = oov_y[idx].tolist()\n",
    "            print(y_list)\n",
    "            print(oov_list)\n",
    "            for k in range(len(y_list)):\n",
    "                wi = y_list[k]\n",
    "                if wi != 1 :\n",
    "                    w = model.output_vocab.get_word(wi)\n",
    "                else:\n",
    "                    w = oov_vocab.get_word(oov_list[k])\n",
    "                gold_toks.append(w)\n",
    "                if w == \"<end>\":\n",
    "                    break\n",
    "            print(\"Gold: \", ' '.join(gold_toks))\n",
    "\n",
    "            pred_toks = []\n",
    "            pred_list = pred_y[idx].tolist()\n",
    "            oov_x_curr = oov_x[idx].tolist()\n",
    "            print(oov_x_curr)\n",
    "            print(pred_list)\n",
    "            for k in range(len(pred_list)):\n",
    "                wi = pred_list[k]\n",
    "                if wi < model.out_vocab_size:\n",
    "                    w = model.output_vocab.get_word(wi)\n",
    "                else:\n",
    "\n",
    "                    w = oov_vocab.get_word(oov_x_curr[wi-model.out_vocab_size])\n",
    "                pred_toks.append(w)\n",
    "                if w == \"<end>\":\n",
    "                    break\n",
    "            print(\"Predict: \",' '.join(pred_toks))\n",
    "        if pred_toks == gold_toks:\n",
    "            num_correct += 1\n",
    "        num_total +=1\n",
    "    print('accuracy', num_correct/num_total)\n",
    "\n",
    "test_batch(test_loader, oov_vocab, model)\n",
    "\n",
    "\n",
    "# In[143]:\n",
    "\n",
    "\n",
    "print([(ex.x_str, ex.y_str) for ex in test_exs])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
