{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "<torch._C.Generator at 0x10bfab3d0>"
=======
       "<torch._C.Generator at 0x7fe856761a10>"
>>>>>>> b0685b9f8b78dd02ec25819e97848d60eeb666da
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1013)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/codegen.csv\")\n",
    "data_x = df[\"utterance\"]\n",
    "data_y = df[\"targets\"]\n",
    "\n",
    "\"\"\"\n",
    "# import dataset\n",
    "with open(\"calculator.dataset\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "data_x, data_y = [], []\n",
    "for line in lines:\n",
    "    if (line[0] == \"(\"):\n",
    "        data_y.append(line.strip())\n",
    "    elif (line != \"\\n\"):\n",
    "        data_x.append(line.strip())\n",
    "\"\"\"\n",
    "# split into test/train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.2)\n",
    "\n",
    "test_x.loc[38] = \"What is the minimum humidity?\"\n",
    "test_y.loc[38] = \"min( WeatherHistory [ 'Humidity' ] )\"\n",
    "\n",
    "test_x.loc[39] = \"What is the lowest humidity?\"\n",
    "test_y.loc[39] = \"min( WeatherHistory [ 'Humidity' ] )\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "copy_mappings = dict()\n",
    "mean = set([\"average\", \"median\", \"center\", \"typical\"])\n",
    "minimum = set([\"minimum\", \"lowest\", \"smallest\"])\n",
    "maximum = set([\"maximum\", \"biggest\", \"highest\", \"largest\"])\n",
    "ranges = set([\"range\", \"ranges\", \"span\", \"spans\"])\n",
    "corr = set([\"correlation\"])\n",
    "lm = set([\"linear\", \"regression\", \"relationship\"])\n",
    "predict = set([\"predict\", \"forecast\", \"predicted\", \"predicting\"])\n",
    "\n",
    "copy_mappings = {\"mean(\":mean, \"minimum(\":minimum, \"maximum(\":maximum, 'ranges(':ranges, \n",
    "                 \"corr(\":corr, \"lm(\":lm, \"predict(\":predict, \"is\":\"'s\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building input and output vocabulary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "{'NULL': 0, 'UNK': 1, '<end>': 2, 'How': 3, 'does': 4, 'temperature': 5, 'feeling_temperature?': 6, 'what': 7, 'is': 8, 'the': 9, 'maximum(': 10, 'recorded?': 11, \"What's\": 12, 'minimum(': 13, 'value?': 14, 'What': 15, 'humidity': 16, 'when': 17, '12?': 18, 'to': 19, 'a': 20, 'change': 21, 'in': 22, 'temperature?': 23, 'Give': 24, 'recorded': 25, 'of': 26, 'data': 27, 'WeatherHistory.': 28, 'you': 29, 'any': 30, 'lm(': 31, 'between': 32, '_': 33, 'and': 34, '_?': 35, 'Please': 36, 'find': 37, 'coldest': 38, 'weather': 39, 'history': 40, 'base.': 41, 'Tell': 42, 'me': 43, 'value.': 44, 'mean(': 45, 'correlated': 46, 'from': 47, 'feeling': 48, 'how': 49, 'affect': 50, 'humidity?': 51, 'Find': 52, 'corr(': 53, 'temperature.': 54, 'Of': 55, 'listed': 56, 'all': 57, 'temperatures?': 58, 'model': 59, 'at': 60, '12': 61, 'Which': 62, 'Can': 63, 'give': 64, 'value': 65, 'variables': 66, 'predict(': 67, 'there': 68, 'Describe': 69, 'degrees': 70, 'by': 71, 'using': 72, 'hot': 73, 'did': 74, 'it': 75, 'get': 76, 'based': 77, 'on': 78, 'dataset?': 79, 'Predict': 80, '12.': 81, 'tell': 82, 'was': 83, 'day?': 84, 'values,': 85, 'which': 86, 'level': 87, 'Create': 88, 'Weather': 89, 'History': 90, 'Does': 91, 'have': 92, 'an': 93, 'can': 94, 'with': 95, 'celsius?': 96, \"what's\": 97, 'mean': 98, 'values': 99, 'for': 100, 'described': 101, 'previous': 102, 'question.': 103, 'b/w': 104, 'extent': 105, 'are': 106, 'be': 107, \"it's\": 108, 'today?': 109, 'What’s': 110, 'higher': 111, 'than': 112, 'actual': 113, '(and': 114, 'vice-versa)?': 115, 'forecasted': 116, 'hottest': 117, 'will': 118, 'feel': 119, 'like': 120, 'temperatures': 121, 'WeatherHistory?': 122, 'listed?': 123, 'entry': 124, 'outside,': 125, 'β̂': 126}\n",
      "{'NULL': 0, 'UNK': 1, '<end>': 2, 'cor(': 3, 'WeatherHistroy': 4, '[': 5, \"'Temperature'\": 6, ']': 7, ',': 8, 'WeatherHistory': 9, \"'FellingTemperature'\": 10, ')': 11, 'max(': 12, 'min(': 13, 'predict(': 14, 'mod': 15, '12': 16, 'lm(': 17, \"'Humidity'\": 18, 'mean(': 19}\n"
=======
      "{'NULL': 0, 'UNK': 1, '<end>': 2, 'What': 3, 'is': 4, 'the': 5, 'maximum': 6, 'temperature': 7, 'in': 8, 'dataset?': 9, 'there': 10, 'a': 11, 'correlation': 12, 'and': 13, 'feeling_temperature?': 14, 'Tell': 15, 'me': 16, 'value': 17, 'of': 18, 'feeling': 19, 'temperature.': 20, 'Give': 21, 'between': 22, 'what': 23, 'minimum': 24, 'is.': 25, \"What's\": 26, 'average': 27, 'celsius?': 28, 'How': 29, 'cold': 30, 'did': 31, 'it': 32, 'get': 33, 'based': 34, 'on': 35, 'Do': 36, 'you': 37, 'any': 38, '_': 39, '_?': 40, 'mean': 41, 'temperature?': 42, 'linear': 43, 'relationship': 44, 'Create': 45, 'model': 46, 'humidity': 47, 'Weather': 48, 'History': 49, 'data': 50, 'when': 51, '12?': 52, 'Can': 53, 'give': 54, 'WeatherHistory?': 55, 'humidity?': 56, 'how': 57, 'does': 58, 'get?': 59, 'Find': 60, 'at': 61, '12': 62, 'degrees.': 63, 'your': 64, 'prediction': 65, 'Is': 66, 'actual': 67, '12.': 68, 'hot': 69, 'lowest': 70, 'coldest': 71, 'regression': 72, 'Describe': 73, 'degrees': 74, 'by': 75, 'using': 76, 'weather': 77, 'history?': 78, 'degree.': 79, 'predicted': 80, 'temperatures': 81, 'highest': 82, 'value?': 83, 'WeatherHistory.': 84, 'change': 85, 'predict': 86, 'Predict': 87, 'value.': 88, 'Of': 89, 'listed': 90, 'be': 91, 'affect': 92, 'from': 93, 'with': 94, 'What’s': 95, 'today?': 96, 'b/w': 97, 'variables': 98, 'Calculate': 99, 'β̂': 100, 'listed?': 101, 'predicting': 102, 'day?': 103, 'hottest': 104, 'will': 105, 'be?': 106, 'correlated': 107, 'recorded?': 108, 'Which': 109, 'like': 110, \"what's\": 111, 'was': 112, 'to': 113, 'ever': 114, 'influence': 115, 'tell': 116}\n",
      "{'NULL': 0, 'UNK': 1, '<end>': 2, 'min(': 3, 'WeatherHistory': 4, '[': 5, \"'Temperature'\": 6, ']': 7, ')': 8, 'cor(': 9, 'WeatherHistroy': 10, ',': 11, \"'FellingTemperature'\": 12, 'max(': 13, 'mean(': 14, 'lm(': 15, \"'Humidity'\": 16, 'predict(': 17, 'mod': 18, '12': 19}\n"
>>>>>>> b0685b9f8b78dd02ec25819e97848d60eeb666da
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class Vocabulary():\n",
    "    END_OF_SENTENCE = '<end>'\n",
    "    NULL = 'NULL'\n",
    "    UNKNOWN = 'UNK'\n",
    "    END_OF_SENTENCE_INDEX = 2\n",
    "    def __init__(self):\n",
    "        self.tok2ind = {self.NULL: 0, self.UNKNOWN: 1, self.END_OF_SENTENCE: 2}\n",
    "        self.ind2tok = {0: self.NULL, 1: self.UNKNOWN, 2: self.END_OF_SENTENCE}\n",
    "    \n",
    "    def add(self, token):\n",
    "        if token not in self.tok2ind:\n",
    "            index = len(self.tok2ind)\n",
    "            self.tok2ind[token] = index\n",
    "            self.ind2tok[index] = token\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tok2ind)\n",
    "    \n",
    "    def get_index(self, word):\n",
    "        if word in self.tok2ind:\n",
    "            return self.tok2ind[word]\n",
    "        return self.tok2ind[self.UNKNOWN]\n",
    "    \n",
    "    def get_word(self, i):\n",
    "        return self.ind2tok[i]\n",
    "\n",
    "    def sentence_to_indices(self, sentence):\n",
    "        words = [x for x in sentence.split(' ')]\n",
    "        words.append(self.END_OF_SENTENCE)\n",
    "        indices = [self.get_index(w) for w in words]\n",
    "        return indices\n",
    "\n",
    "def build_vocab(examples):\n",
    "    counts = Counter()\n",
    "    for ex in examples:\n",
    "        words = [w for w in ex.split(' ') if w.strip()]\n",
    "        counts.update(words)\n",
    "    \n",
    "    word_list = [w for w in counts if counts[w] > 1]\n",
    "    for i in range(len(word_list)):\n",
    "        for k, v in copy_mappings.items():\n",
    "            if word_list[i] in v:\n",
    "                word_list[i] = k\n",
    "                break\n",
    "    word_dict = Vocabulary()\n",
    "    for w in word_list:\n",
    "        word_dict.add(w)\n",
    "    return word_dict\n",
    "\n",
    "input_vocab = build_vocab(train_x)\n",
    "output_vocab = build_vocab(train_y)\n",
    "print(input_vocab.tok2ind)\n",
    "print(output_vocab.tok2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'curr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-d9c6038c29b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mword_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0minput_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0moutput_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# print(train_y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-85-d9c6038c29b5>\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m#         curr  = replace_punct(ex)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcurr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'curr' is not defined"
     ]
    }
   ],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# class Vocabulary():\n",
    "#     END_OF_SENTENCE = '<end>'\n",
    "#     NULL = 'NULL'\n",
    "#     UNKNOWN = 'UNK'\n",
    "#     END_OF_SENTENCE_INDEX = 2\n",
    "#     def __init__(self):\n",
    "#         self.tok2ind = {self.NULL: 0, self.UNKNOWN: 1, self.END_OF_SENTENCE: 2}\n",
    "#         self.ind2tok = {0: self.NULL, 1: self.UNKNOWN, 2: self.END_OF_SENTENCE}\n",
    "    \n",
    "#     def add(self, token):\n",
    "#         if token not in self.tok2ind:\n",
    "#             index = len(self.tok2ind)\n",
    "#             self.tok2ind[token] = index\n",
    "#             self.ind2tok[index] = token\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.tok2ind)\n",
    "    \n",
    "#     def get_index(self, word):\n",
    "#         if word in self.tok2ind:\n",
    "#             return self.tok2ind[word]\n",
    "#         return self.tok2ind[self.UNKNOWN]\n",
    "    \n",
    "#     def get_word(self, i):\n",
    "#         return self.ind2tok[i]\n",
    "\n",
    "#     def sentence_to_indices(self, sentence):\n",
    "#         words = [x for x in sentence.split(' ')]\n",
    "#         words.append(self.END_OF_SENTENCE)\n",
    "#         indices = [self.get_index(w) for w in words]\n",
    "#         return indices\n",
    "    \n",
    "# import string\n",
    "\n",
    "# def replace_punct(sentence):\n",
    "#     \"\"\"\n",
    "#     Replaces with punctuation with a space + punctuation\n",
    "#     \"\"\"\n",
    "#     result = \"\"\n",
    "#     for c in (sentence.lower()):\n",
    "#         if (c != '(' and c in string.punctuation):\n",
    "#             result += \" \" \n",
    "#         result += c\n",
    "        \n",
    "#     return result\n",
    "\n",
    "# def build_vocab(examples):\n",
    "#     counts = Counter()\n",
    "#     for ex in examples:\n",
    "# #         curr  = replace_punct(ex)\n",
    "\n",
    "#         words = [w for w in curr.split(' ') if w.strip()]\n",
    "#         counts.update(words)\n",
    "    \n",
    "#     word_list = [w for w in counts if counts[w] > 1]\n",
    "# #     for i in range(len(word_list)):\n",
    "# #         for k, v in copy_mappings.items():\n",
    "# #             if word_list[i] in v:\n",
    "# #                 word_list[i] = k\n",
    "# #                 break\n",
    "#     word_dict = Vocabulary()\n",
    "#     for w in word_list:\n",
    "#         word_dict.add(w)\n",
    "#     return word_dict\n",
    "\n",
    "# input_vocab = build_vocab(train_x)\n",
    "# output_vocab = build_vocab(train_y)\n",
    "# # print(train_y)\n",
    "# print(input_vocab.tok2ind)\n",
    "# print(output_vocab.tok2ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "x ['How', 'does', 'temperature', 'influence', 'feeling_temperature?'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['what', 'is', 'the', 'maximum(', 'temperature', 'recorded?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x [\"What's\", 'the', 'minimum(', 'temperature', 'value?'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'minimum(', 'temperature', 'value?'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'humidity', 'when', 'temperature', 'is', '12?'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['How', 'does', 'humidity', 'respond', 'to', 'a', 'change', 'in', 'temperature?'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['Give', 'the', 'maximum(', 'recorded', 'temperature', 'of', 'the', 'data', 'WeatherHistory.'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['How', 'high', 'does', 'the', 'temperature', 'go?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Do', 'you', 'notice', 'any', 'lm(', 'lm(', 'between', '_', 'and', '_?'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['Please', 'find', 'the', 'coldest', 'temperature', 'in', 'the', 'weather', 'history', 'data', 'base.', 'is'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Tell', 'me', 'the', 'maximum(', 'temperature', 'value.', 'is'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x [\"What's\", 'the', 'mean(', 'temperature?'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['How', 'correlated', 'is', 'temperature', 'from', 'feeling', 'temperature?', 'is'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['how', 'does', 'temperature', 'affect', 'humidity?'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['Find', 'the', 'corr(', 'between', 'temperature', 'and', 'feeling', 'temperature.', 'is'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'humidity', 'when', 'the', 'temperature', 'is', '12?', 'is'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['Of', 'the', 'listed', 'temperatures,', 'what', 'is', 'the', 'mean?'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x [\"What's\", 'the', 'max', 'temperature', 'of', 'all', 'temperatures?'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Find', 'the', 'temperature', 'lm(', 'model', 'at', '12', 'degrees.'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['Find', 'the', 'minimum(', 'temperature', 'value.', 'is'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x [\"What's\", 'the', 'minimum(', 'temperature', 'of', 'all', 'temperatures?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x [\"What's\", 'the', 'lm(', 'between', 'temperature', 'and', 'humidity?', 'is'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x [\"What's\", 'the', 'minimum(', 'temperature', 'in', 'weather', 'history?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'lm(', 'lm(', 'of', '_', 'and', '_?'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'maximum(', 'temperature', 'value?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Which', 'listed', 'temperature', 'is', 'the', 'greatest?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Can', 'you', 'give', 'the', 'corr(', 'value', 'between', 'the', 'variables', 'temperature', 'and', 'feeling_temperature?'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'lm(', 'model', 'of', 'temperature', 'predict(', 'humidity?', 'is'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['is', 'there', 'a', 'corr(', 'beteeen', 'temperature', 'and', 'feeling_temperature?'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['Describe', 'the', 'lm(', 'model', 'at', 'temp', '=', '12', 'degrees', 'by', 'using', 'prediction.'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['How', 'hot', 'did', 'it', 'get', 'based', 'on', 'the', 'dataset?'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Given', 'that', 'temperature', 'is', '12', 'predict(', 'what', 'the', 'value', 'of', 'humidity', 'would', 'be.'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['What', 'is', 'the', 'corr(', 'between', 'the', 'variables', 'temperature', 'and', 'feeling_temperature?'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['Predict', 'the', 'humidity', 'when', 'temperature', 'is', '12.'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['Can', 'you', 'tell', 'me', 'what', 'the', 'temperature', 'was', 'on', 'the', 'coldest', 'day?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Can', 'a', 'change', 'in', 'temperature', 'predict(', 'a', 'change', 'in', 'humidity?'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['Of', 'the', 'listed', 'temperature', 'values,', 'which', 'is', 'the', 'lowest?'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Predict', 'the', 'humidity', 'level', 'when', 'the', 'temperature', 'is', '12.', 'is'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['is', 'the', 'temperature', 'accurate', 'to', 'how', 'it', 'feels?'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['Create', 'a', 'lm(', 'model', 'of', 'humidity', 'through', 'temperature', 'in', 'the', 'Weather', 'History', 'data', 'frame.'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['Does', 'temperature', 'have', 'an', 'affect', 'on', 'feeling_temperature?'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'corr(', 'between', 'temperature', 'and', 'feeling', 'temperature?'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['Based', 'on', 'the', 'lm(', 'can', 'you', 'find', 'the', 'predict(', 'value', 'of', 'humidity', 'when', 'temperature', 'is', '12', 'degrees', 'celsius'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['Tell', 'me', 'the', 'mean(', 'temperature.'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'corr(', 'between', '_', 'and', '_?'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['Find', 'the', 'mean(', 'temperature.', 'is'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Create', 'a', 'lm(', 'model', 'of', 'temperature', 'on', 'humidity.'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'corr(', 'between', 'temperature', 'and', 'feeling', 'temperature', 'in', 'the', 'database.'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['Find', 'a', 'lm(', 'lm(', 'between', 'humidity', 'and', 'temperature'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['is', 'temperature', 'correlated', 'with', 'humidity?'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x [\"What's\", 'the', 'predict(', 'value', 'of', 'humidity', 'when', 'temperature', 'is', '12', 'degrees', 'celsius?'] ['predict(', 'mod', ',', '12', ')']\n",
      "x [\"what's\", 'the', 'mean', 'temperature?'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Please', 'give', 'the', 'predict(', 'values', 'for', 'the', 'model', 'described', 'in', 'the', 'previous', 'question.'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['What', 'is', 'the', 'mean(', 'temperature?', 'is'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x [\"What's\", 'the', 'lm(', 'b/w', 'temperature', 'and', 'feeling_temperature?'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x [\"What's\", 'the', 'lm(', 'between', 'humidity', 'and', 'temperature?'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['To', 'what', 'extent', 'are', 'temperature', 'and', 'humidity?', 'is'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['What', 'do', 'you', 'think', 'the', 'humidity', 'should', 'be', 'when', 'the', 'temperature', 'is', '12?'] ['predict(', 'mod', ',', '12', ')']\n",
      "x [\"What's\", 'the', 'lm(', 'b/w', 'temperature', 'and', 'humidity?'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x [\"What's\", 'the', 'coldest', 'temperature?'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Tell', 'me', 'what', 'the', 'minimum(', 'temperature', 'is.', 'is', 'is', 'is'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Tell', 'me', 'the', 'corr(', 'between', 'temperature', 'and', 'feeling', 'temperature.', 'is'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['Give', 'me', 'the', 'expected', 'humidity', 'when', 'temperature', 'is', '12.', 'is'] ['predict(', 'mod', ',', '12', ')']\n",
      "x [\"what's\", 'the', 'coldest', \"it's\", 'ever', 'been?'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Could', 'you', 'check', 'the', 'mean(', 'temperature', 'today?'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What’s', 'the', 'coldest', 'temperature', 'today?'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Give', 'me', 'the', 'maximum(', 'of', 'temperature.'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Is', 'the', 'feeling', 'temperature', 'higher', 'than', 'the', 'actual', 'temperature', '(and', 'vice-versa)?'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'minimum(', 'temperature', 'value?'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'humidity', 'at', 'the', 'current', 'temperature?'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['What', 'is', 'the', 'humidity', 'at', 'the', 'predict(', 'temperature', 'at', '12', 'pm?'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['How', 'strong', 'is', 'the', 'lm(', 'lm(', 'between', 'humidity', 'and', 'temperature?'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['what', 'is', 'the', 'mean(', 'temperature?'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'maximum(', 'of', 'temperature?'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Tell', 'me', 'the', 'minimum(', 'temperature', 'value.', 'is'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['can', 'I', 'have', 'the', 'forecasted', 'humidity', 'level', 'for', 'when', \"it's\", '12', 'degrees?', 'is'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['to', 'what', 'extent', 'does', 'the', 'temperature', 'forecasted', 'match', 'the', 'actual', 'temperature?'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x [\"What's\", 'the', 'hottest', 'temperature?'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['How', 'are', 'temperature', 'and', 'humidity', 'correlated?', 'is'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['Can', 'you', 'tell', 'me', 'difference', 'in', 'lm(', 'of', 'humidity', 'and', 'temperature?'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['Give', 'me', 'the', 'maximum(', 'temperature', 'value.'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'corr(', 'between', 'temperature', 'and', 'feeling', 'temperature?'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'mean', 'temperature?'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['when', 'it', 'is', '12', 'degrees', 'Celsius,', 'what', 'will', 'the', 'humidity', 'be?', 'is', 'is'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['how', 'hot', 'does', 'it', 'get?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x [\"What's\", 'the', 'predict(', 'humidity', 'whenm', 'temperature', 'is', '12?'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['What', 'is', 'the', 'minimum(', 'temperature', 'value?'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Describe', 'the', 'lm(', 'of', 'each', 'variable', 'in', 'the', 'Weather', 'History', 'data', 'frame', 'by', 'creating', 'a', 'lm(', 'model.'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x [\"What's\", 'the', 'lm(', 'lm(', 'of', 'humidity', 'on', 'temperature?'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['Describe', 'the', 'lm(', 'of', 'temperature', 'and', 'feeling', 'temperature', 'based', 'on', 'their', 'correlation.'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['does', 'the', 'weather', 'feel', 'like', 'what', 'was', 'forecasted?'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['Can', 'you', 'make', 'a', 'lm(', 'between', 'humidity', 'and', 'temperature?'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['At', '12', 'degrees,', \"what's\", 'the', 'predict(', 'humidity?'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['What', 'is', 'the', 'maximum(', 'temperature', 'value?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['When', 'the', 'temperature', 'is', '12,', 'what', 'is', 'the', 'value', 'of', 'humidity?', 'is'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['Can', 'you', 'calculate', 'the', 'predict(', 'values', 'for', 'the', 'model', 'described', 'in', 'the', 'previous', 'question?'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['What', 'is', 'the', 'maximum(', 'temperature', 'of', 'the', 'Weather', 'History', 'dataset?'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x [\"What's\", 'the', 'corr(', 'between', 'actual', 'and', 'feeling', 'temperature?'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'mean', 'of', 'the', 'temperatures', 'in', 'the', 'data', 'WeatherHistory?'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'minimum(', 'temperature', 'of', 'the', 'Weather', 'History', 'dataset?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What’s', 'the', 'minimum(', 'temperature', 'today?'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What’s', 'the', 'mean(', 'temperature', 'today?'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'minimum(', 'temperature', 'listed?'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'maximum(', 'temperature', 'entry', 'in', 'the', 'dataset?', 'is'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Give', 'the', 'minimum(', 'temperature', 'of', 'the', 'data', 'WeatherHistory.'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x [\"What's\", 'the', 'mean(', 'of', 'temperature?'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'maximum(', 'temperature', 'value?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Can', 'you', 'give', 'me', 'the', 'maximum(', 'recorded', 'temperature', 'of', 'the', 'data', 'WeatherHistory?'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What’s', 'the', 'lm(', 'between', '_', 'and', '_?'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['Of', 'the', 'listed', 'temperature', 'values,', 'which', 'is', 'the', 'highest?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Can', 'you', 'tell', 'me', 'what', 'the', 'temperature', 'was', 'on', 'the', 'hottest', 'day?'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'mean', 'temperature?'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Can', 'you', 'predict(', 'from', 'the', 'model', 'what', 'humidity', 'is', 'associated', 'with', 'temperature', '12?'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['What', 'is', 'the', 'maximum(', 'of', 'the', 'temperatures', 'in', 'the', 'data', 'WeatherHistory?'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['is', 'there', 'a', 'lm(', 'lm(', 'between', 'temperature', 'and', 'humidity?'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'humidity', 'when', 'the', 'temperature', 'is', '12?'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['Give', 'me', 'the', 'minimum(', 'temperature', 'degree.', 'is'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What’s', 'the', 'maximum(', 'temperature', 'today?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'maximum(', 'temperature', 'listed?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'minimum(', 'temperature?', 'is'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Can', 'you', 'give', 'me', 'the', 'mean(', 'temperature', 'of', 'the', 'data', 'WeatherHistory?'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x [\"What's\", 'the', 'maximum(', 'temperature', 'value?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Can', 'you', 'create', 'a', 'lm(', 'model', 'of', 'temperature', 'on', 'humidity?'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'mean(', 'temperature?'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x [\"What's\", 'the', 'temperature', 'on', 'any', 'mean(', 'day?'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Tell', 'me', 'what', 'it', 'feels', 'like', 'outside,', 'and', \"what's\", 'the', 'actual', 'temperature?'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['what', 'is', 'the', 'mean(', 'temperature?'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Give', 'me', 'the', 'minimum(', 'temperature', 'value.'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['How', 'cold', 'did', 'it', 'get', 'based', 'on', 'the', 'dataset?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Tell', 'me', 'the', 'mean(', 'temperature.', 'is'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Find', 'the', 'hottest', 'temperature', 'in', 'the', 'database', 'is'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Does', 'temperature', 'have', 'an', 'affect', 'on', 'humidity?'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['Can', 'you', 'take', 'the', 'mean(', 'of', 'all', 'temperatures', 'in', 'the', 'weather', 'history', 'data', 'base.'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Find', 'the', 'total', 'mean', 'temperature.'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What', 'temperature', 'does', 'it', 'feel', 'like', 'outside,', 'and', 'tell', 'me', 'the', 'actual', 'temperature.'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'minimum(', 'temperature', 'entry', 'in', 'the', 'dataset?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x [\"What's\", 'mean', 'of', 'the', 'temperature', 'in', 'the', 'data', 'set?'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Which', 'listed', 'temperature', 'is', 'the', 'least?'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'corr(', 'between', 'temperature', 'and', 'feeling_temperature?'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['Calculate', 'the', 'is', 'μ̂', ',', 'β̂', '1,', 'and', 'β̂', '2', 'using', 'the', 'predict(', 'function', 'and', 'model', 'described', 'in', 'the', 'previous', 'question.'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['what', 'is', 'the', 'minimum(', 'temperature', 'recorded?'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Can', 'you', 'tell', 'me', 'what', 'the', 'mean(', 'temperature', 'of', 'the', 'dataset', 'is?'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['how', 'is', 'the', 'temperature', 'usually?'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['what', 'will', 'the', 'humidity', 'be', 'when', \"it's\", '12', 'degrees', 'celsius?'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['By', 'how', 'much', 'is', 'the', 'feeling', 'temperature', 'higher', 'than', 'the', 'actual', 'temperature', '(and', 'vice-versa)?'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['What', 'is', 'your', 'prediction', 'of', 'humidity', 'when', 'temperature', 'is', '12?'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['What', 'is', 'the', 'minimum(', 'is', 'of', 'temperature?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['what', 'is', 'the', 'minimum(', 'temperature', 'recorded?'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'lm(', 'equation', 'of', 'temperature', 'predict(', 'humidity?'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['How', 'correlated', 'are', 'temperature', 'and', 'humidity?'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x [\"What's\", 'the', 'mean', 'temperature?', 'is'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'minimum(', 'of', 'the', 'temperatures', 'in', 'the', 'data', 'WeatherHistory?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Tell', 'me', 'what', 'the', 'mean', 'of', 'the', 'temperature', 'is.', 'is'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['how', 'cold', 'does', 'it', 'get?'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x [\"What's\", 'the', 'humidity', 'at', '12', 'degrees?'] ['predict(', 'mod', ',', '12', ')']\n",
      "x [\"What's\", 'the', 'hottest', 'temperature?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'actual', 'temperature', 'and', 'feeling', 'temperature?'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['Give', 'me', 'the', 'corr(', 'between', 'temperature', 'and', 'feeling', 'temperature.', 'is'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['Give', 'me', 'the', 'mean', 'of', 'temperature.'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['what', 'is', 'your', 'prediction', 'of', 'humidity', 'when', 'the', 'temperature', 'is', '12'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['Is', 'there', 'a', 'corr(', 'between', 'actual', 'and', 'feeling', 'temperature?'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['Give', 'me', 'the', 'actual', 'temperature', 'and', 'feeling', 'temperature.'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['Calculate', 'the', 'corr(', 'value', 'between', 'the', 'variables', 'temperature', 'and', 'feeling_temperature.'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['Temperature', 'is', '12', 'and', 'humidity', 'is', 'what?'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['Do', 'you', 'see', 'any', 'corr(', 'between', '_', 'and', '_?'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['What', 'would', 'the', 'humidity', 'be', 'given', 'a', 'temperature', 'of', '12?'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['COuld', 'you', 'find', 'the', 'corr(', 'between', 'actual', 'and', 'feeling', 'temperature?'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['How', 'does', 'temperature', 'influence', 'humidity?'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['Find', 'the', 'maximum(', 'temperature', 'value.', 'is'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'lm(', 'model', 'of', 'temperature', 'predict(', 'humidity', '?'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'mean(', 'temperature', 'of', 'the', 'Weather', 'History', 'dataset?'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Tell', 'me', 'the', 'numeric', 'corr(', 'value', 'of', 'temperature', 'and', 'feeling', 'temperature.'] ['cor(', 'WeatherHistroy', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'FellingTemperature'\", ']', ')']\n",
      "x ['Fit', 'a', 'lm(', 'model', 'between', 'humidity', 'and', 'temperature.', 'is'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['Look', 'for', 'a', 'lm(', 'lm(', 'between', '_', 'and', '_.'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['what', 'is', 'the', 'maximum(', 'temperature', 'recorded?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['what', 'is', 'the', 'lm(', 'between', 'temperature', 'and', 'humidity?'] ['lm(', 'WeatherHistory', '[', \"'Temperature'\", ']', ',', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'maximum(', 'temperature?', 'is'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Give', 'the', 'mean', 'temperature', 'of', 'the', 'data', 'WeatherHistory.'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x [\"What's\", 'the', 'maximum(', 'temperature', 'in', 'weather', 'history?'] ['min(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x [\"What's\", 'the', 'coldest', 'temperature?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['At', '12', 'degrees,', 'what', 'will', 'the', 'humidity', 'be?'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['Predict', 'the', 'the', 'lm(', 'model', 'when', 'the', 'temperature', 'is', 'at', '12', 'degrees.'] ['predict(', 'mod', ',', '12', ')']\n",
      "x ['what', 'is', 'the', 'mean(', 'temperature?'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Give', 'me', 'the', 'maximum(', 'temperature', 'degree.', 'is'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x [\"What's\", 'the', 'mean(', 'temperature', 'in', 'celsius?'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Can', 'you', 'give', 'me', 'the', 'minimum(', 'temperature', 'of', 'the', 'data', 'WeatherHistory?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['Give', 'the', 'mean(', 'temperature.'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['how', 'hot', 'has', 'it', 'ever', 'gotten?'] ['max(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x [\"What's\", 'the', 'mean(', 'temperature?', 'is'] ['mean(', 'WeatherHistory', '[', \"'Temperature'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'minimum(', 'humidity?'] ['min(', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
      "x ['What', 'is', 'the', 'minimum(', 'humidity?'] ['min(', 'WeatherHistory', '[', \"'Humidity'\", ']', ')']\n",
=======
      "\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 6x9]\n",
      "\n",
>>>>>>> b0685b9f8b78dd02ec25819e97848d60eeb666da
      "\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x5]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x13]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 6x9]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 5x10]\n",
      "\n",
      "\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x5]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 5x13]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x10]\n",
      "\n",
      "\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 17 \n",
      "    0     0     0     0     0\n",
      "    0     0     0     0     0\n",
      "    0     0     0     0     0\n",
      "    0     0     1     0     0\n",
      "    0     0     0     0     0\n",
      "[torch.FloatTensor of size 5x18]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x9]\n",
      "\n",
      "\n",
<<<<<<< HEAD
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 6x10]\n",
=======
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     1     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 5x7]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x9]\n",
>>>>>>> b0685b9f8b78dd02ec25819e97848d60eeb666da
      "\n",
      "\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x5]\n",
      "\n",
      "\n",
<<<<<<< HEAD
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  1  0\n",
      " 0  0  0  0  0  0\n",
      "[torch.FloatTensor of size 5x6]\n",
      "\n",
      "\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      "[torch.FloatTensor of size 6x4]\n",
=======
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 5x7]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x11]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 5x10]\n",
>>>>>>> b0685b9f8b78dd02ec25819e97848d60eeb666da
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 6x9]\n",
      "\n",
      "\n",
<<<<<<< HEAD
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x10]\n",
=======
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 6x7]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x7]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x7]\n",
      "\n",
      "\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 13 \n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 6x14]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 5x13]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 6x12]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x9]\n",
>>>>>>> b0685b9f8b78dd02ec25819e97848d60eeb666da
      "\n",
      "\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x6]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     1\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 5x11]\n",
      "\n",
      "\n",
<<<<<<< HEAD
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x9]\n",
=======
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x6]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 6x12]\n",
      "\n",
      "\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x6]\n",
>>>>>>> b0685b9f8b78dd02ec25819e97848d60eeb666da
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x8]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x10]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     1     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 5x7]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x9]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 5x10]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x10]\n",
      "\n",
      "\n",
      "    0     0     0     0     0\n",
      "    0     0     0     0     0\n",
      "    0     0     0     0     0\n",
      "    0     0     0     0     0\n",
      "    0     0     0     0     0\n",
      "    0     0     0     0     0\n",
      "    0     0     0     0     0\n",
      "    0     0     0     0     0\n",
      "    0     0     0     0     0\n",
      "    0     0     0     0     0\n",
      "    0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x5]\n",
      "\n",
      "\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x6]\n",
      "\n",
      "\n",
<<<<<<< HEAD
      "    0     0     0     1     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x10]\n",
      "\n",
      "\n",
      "    0     0     0     1     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 6x10]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x11]\n",
      "\n",
      "\n",
      "    0     0     1     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x9]\n",
      "\n",
      "\n",
      "    0     0     0     1     1     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x9]\n",
      "\n",
      "\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x6]\n",
      "\n",
      "\n",
      "    0     0     0     1     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x8]\n",
      "\n",
      "\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x6]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 6x8]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 6x7]\n",
      "\n",
      "\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      "[torch.FloatTensor of size 6x4]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "    0     1     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 5x8]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     1     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 5x12]\n",
      "\n",
      "\n",
      " 0  0  0  1  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x5]\n",
=======
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 13 \n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 5x14]\n",
      "\n",
      "\n",
      "    0     0     0     0     0     0\n",
      "    0     0     0     0     0     0\n",
      "    0     0     0     0     0     0\n",
      "    0     0     0     0     0     0\n",
      "    0     0     0     0     0     0\n",
      "    0     0     0     0     0     0\n",
      "    0     0     0     0     0     0\n",
      "    0     0     0     0     0     0\n",
      "    0     0     0     0     0     0\n",
      "    0     0     0     0     0     0\n",
      "    0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 11x6]\n",
>>>>>>> b0685b9f8b78dd02ec25819e97848d60eeb666da
      "\n",
      "\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 6x7]\n",
      "\n",
      "\n",
      " 0  0  1  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x6]\n",
      "\n",
      "\n",
<<<<<<< HEAD
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 6x11]\n",
      "\n",
      "\n",
      " 0  0  1  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      "[torch.FloatTensor of size 6x4]\n",
      "\n",
      "\n",
=======
>>>>>>> b0685b9f8b78dd02ec25819e97848d60eeb666da
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      " 0  0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x6]\n",
      "\n",
      "\n",
<<<<<<< HEAD
      " 0  0  1  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x5]\n",
      "\n",
      "\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x5]\n",
      "\n",
      "\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      " 0  0  0  0  0\n",
      "[torch.FloatTensor of size 6x5]\n",
=======
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 13 \n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 11x14]\n",
>>>>>>> b0685b9f8b78dd02ec25819e97848d60eeb666da
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "class Example():\n",
    "    def __init__(self, x_str, y_str, input_vocab, output_vocab, copy_dict):\n",
    "        self.x_str = x_str\n",
    "        self.y_str = y_str\n",
    "        self.x_toks = x_str.split(' ')\n",
    "        for i in range(len(self.x_toks)):\n",
    "            for k, v in copy_dict.items():\n",
    "                if self.x_toks[i] in v:\n",
    "                    self.x_toks[i] = k\n",
    "        \n",
    "        self.y_toks = y_str.split(' ')\n",
    "        \n",
    "        self.input_vocab = input_vocab\n",
    "        self.output_vocab = output_vocab\n",
    "        self.x_inds = torch.LongTensor(input_vocab.sentence_to_indices(x_str))\n",
    "        self.y_inds = torch.LongTensor(output_vocab.sentence_to_indices(y_str))\n",
    "        \n",
    "        # for copying\n",
    "        self.y_in_x_inds = torch.FloatTensor(([[int(x_tok == y_tok) for x_tok in self.x_toks] for y_tok in self.y_toks])) \n",
    "        print(\"x\", self.x_toks, self.y_toks)\n",
    "# In order to use PyTorch's data loader\n",
    "class ReaderDataset(Dataset):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.examples[index]\n",
    "    \n",
    "train_exs = []\n",
    "\n",
    "for x,y in zip(train_x, train_y):\n",
    "    train_exs.append(Example(x, y, input_vocab, output_vocab, copy_mappings))\n",
    "train_dataset = ReaderDataset(train_exs)\n",
    "\n",
    "test_exs = []\n",
    "for x,y in zip(test_x, test_y):\n",
    "    test_exs.append(Example(x, y, input_vocab, output_vocab, copy_mappings))\n",
    "test_dataset = ReaderDataset(test_exs)\n",
    "\n",
    "for x in test_dataset:\n",
    "    print(x.y_in_x_inds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize individual examples and organize them into batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\n",
<<<<<<< HEAD
      "    3     1     8  ...      0     0     0\n",
      "    7     8     9  ...      0     0     0\n",
      "   52     9     1  ...      0     0     0\n",
      "       ...          ⋱          ...       \n",
      "   15     8     1  ...      0     0     0\n",
      "   24     9     1  ...      0     0     0\n",
      "   15     8     9  ...      0     0     0\n",
      "[torch.LongTensor of size 100x22]\n",
      ", \n",
      "   10\n",
      "   28\n",
      "   50\n",
      "   79\n",
      "   96\n",
      "  115\n",
      "  145\n",
      "  165\n",
      "  189\n",
      "  209\n",
      "  226\n",
      "  250\n",
      "  269\n",
      "  297\n",
      "  326\n",
      "  335\n",
      "  360\n",
      "  381\n",
      "  402\n",
      "  426\n",
      "  452\n",
      "  470\n",
      "  492\n",
      "  512\n",
      "  534\n",
      "  557\n",
      "  578\n",
      "  599\n",
      "  623\n",
      "  648\n",
      "  669\n",
      "  689\n",
      "  709\n",
      "  731\n",
      "  761\n",
      "  776\n",
      "  804\n",
      "  823\n",
      "  845\n",
      "  868\n",
      "  886\n",
      "  909\n",
      "  929\n",
      "  951\n",
      "  976\n",
      " 1003\n",
      " 1019\n",
      " 1040\n",
      " 1061\n",
      " 1089\n",
      " 1105\n",
      " 1130\n",
      " 1149\n",
      " 1178\n",
      " 1197\n",
      " 1219\n",
      " 1236\n",
      " 1264\n",
      " 1288\n",
      " 1310\n",
      " 1332\n",
      " 1350\n",
      " 1370\n",
      " 1396\n",
      " 1416\n",
      " 1437\n",
      " 1458\n",
      " 1483\n",
      " 1501\n",
      " 1525\n",
      " 1561\n",
      " 1568\n",
      " 1591\n",
      " 1612\n",
      " 1636\n",
      " 1657\n",
      " 1683\n",
      " 1700\n",
      " 1729\n",
      " 1747\n",
      " 1774\n",
      " 1791\n",
      " 1814\n",
      " 1833\n",
      " 1852\n",
      " 1884\n",
      " 1898\n",
      " 1922\n",
      " 1946\n",
      " 1966\n",
      " 1985\n",
      " 2011\n",
      " 2036\n",
      " 2060\n",
      " 2080\n",
      " 2101\n",
      " 2121\n",
      " 2144\n",
      " 2164\n",
      " 2188\n",
=======
      "   26     5    82  ...      0     0     0\n",
      "   26     5    12  ...      0     0     0\n",
      "   87     5     5  ...      0     0     0\n",
      "       ...          ⋱          ...       \n",
      "   21    16     5  ...      0     0     0\n",
      "   21    16     5  ...      0     0     0\n",
      "   57    58     7  ...      0     0     0\n",
      "[torch.LongTensor of size 100x22]\n",
      ", \n",
      "    5\n",
      "   30\n",
      "   56\n",
      "   78\n",
      "  102\n",
      "  117\n",
      "  138\n",
      "  161\n",
      "  181\n",
      "  203\n",
      "  227\n",
      "  246\n",
      "  271\n",
      "  296\n",
      "  316\n",
      "  339\n",
      "  358\n",
      "  384\n",
      "  404\n",
      "  426\n",
      "  447\n",
      "  467\n",
      "  489\n",
      "  511\n",
      "  534\n",
      "  560\n",
      "  581\n",
      "  598\n",
      "  624\n",
      "  649\n",
      "  673\n",
      "  688\n",
      "  712\n",
      "  738\n",
      "  754\n",
      "  776\n",
      "  802\n",
      "  826\n",
      "  848\n",
      "  870\n",
      "  886\n",
      "  911\n",
      "  935\n",
      "  955\n",
      "  975\n",
      "  996\n",
      " 1020\n",
      " 1043\n",
      " 1064\n",
      " 1084\n",
      " 1111\n",
      " 1127\n",
      " 1152\n",
      " 1176\n",
      " 1193\n",
      " 1218\n",
      " 1243\n",
      " 1259\n",
      " 1281\n",
      " 1308\n",
      " 1332\n",
      " 1351\n",
      " 1376\n",
      " 1391\n",
      " 1418\n",
      " 1441\n",
      " 1460\n",
      " 1486\n",
      " 1504\n",
      " 1525\n",
      " 1557\n",
      " 1568\n",
      " 1590\n",
      " 1610\n",
      " 1639\n",
      " 1656\n",
      " 1684\n",
      " 1704\n",
      " 1722\n",
      " 1744\n",
      " 1768\n",
      " 1790\n",
      " 1810\n",
      " 1832\n",
      " 1855\n",
      " 1875\n",
      " 1903\n",
      " 1924\n",
      " 1943\n",
      " 1968\n",
      " 1989\n",
      " 2012\n",
      " 2029\n",
      " 2050\n",
      " 2077\n",
      " 2111\n",
      " 2117\n",
      " 2141\n",
      " 2166\n",
      " 2183\n",
>>>>>>> b0685b9f8b78dd02ec25819e97848d60eeb666da
      "[torch.LongTensor of size 100]\n",
      ", \n",
      "    0     0     0  ...      1     1     1\n",
      "    0     0     0  ...      1     1     1\n",
      "    0     0     0  ...      1     1     1\n",
      "       ...          ⋱          ...       \n",
      "    0     0     0  ...      1     1     1\n",
      "    0     0     0  ...      1     1     1\n",
      "    0     0     0  ...      1     1     1\n",
      "[torch.ByteTensor of size 100x22]\n",
      ", \n",
<<<<<<< HEAD
      "   17     9     5  ...      7    11     2\n",
      "   13     9     5  ...      0     0     0\n",
      "   13     9     5  ...      0     0     0\n",
      "       ...          ⋱          ...       \n",
      "   14    15     8  ...      0     0     0\n",
      "   12     9     5  ...      0     0     0\n",
      "   12     9     5  ...      0     0     0\n",
=======
      "   13     4     5  ...      0     0     0\n",
      "    9    10     5  ...      7     8     2\n",
      "   17    18    11  ...      0     0     0\n",
      "       ...          ⋱          ...       \n",
      "    3     4     5  ...      0     0     0\n",
      "    9    10     5  ...      7     8     2\n",
      "   15     4     5  ...      7     8     2\n",
>>>>>>> b0685b9f8b78dd02ec25819e97848d60eeb666da
      "[torch.LongTensor of size 100x12]\n",
      ", \n",
      "    1     1     1  ...      1     1     1\n",
      "    1     1     1  ...      0     0     0\n",
      "    1     1     1  ...      0     0     0\n",
      "       ...          ⋱          ...       \n",
      "    1     1     1  ...      0     0     0\n",
<<<<<<< HEAD
      "    1     1     1  ...      0     0     0\n",
      "    1     1     1  ...      0     0     0\n",
=======
      "    1     1     1  ...      1     1     1\n",
      "    1     1     1  ...      1     1     1\n",
>>>>>>> b0685b9f8b78dd02ec25819e97848d60eeb666da
      "[torch.ByteTensor of size 100x12]\n",
      ", \n",
      "( 0 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "\n",
      "( 1 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "\n",
      "( 2 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "... \n",
      "\n",
      "(97 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "\n",
      "(98 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "\n",
      "(99 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "[torch.FloatTensor of size 100x12x22]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# vectorize batch data\n",
    "def vectorize(batch):\n",
    "    max_input_length = max([ex.x_inds.size(0) for ex in batch])\n",
    "    x = torch.LongTensor(len(batch), max_input_length).zero_() # initialize to 0\n",
    "    x_mask = torch.ByteTensor(len(batch), max_input_length).fill_(1) # mask used in softmax\n",
    "    x_lens = torch.LongTensor(len(batch)).zero_()\n",
    "    for i, ex in enumerate(batch):\n",
    "        x[i, :ex.x_inds.size(0)].copy_(ex.x_inds)\n",
    "        x_mask[i, :ex.x_inds.size(0)].fill_(0)\n",
    "        ###CHANGE: x_lens store the last index of each sequence. i*max_input_length is added so that later we can use \n",
    "        ###torch.index_select to get the last hidden states from a 2D tensor (batch_size*max_input_length, embedding_dim)\n",
    "        x_lens[i] = i*max_input_length+ex.x_inds.size(0)-1 \n",
    "    \n",
    "    max_output_length = max([ex.y_inds.size(0) for ex in batch])\n",
    "    y = torch.LongTensor(len(batch), max_output_length).zero_()\n",
    "    y_mask = torch.ByteTensor(len(batch), max_output_length).zero_() # for masked_select\n",
    "    for i, ex in enumerate(batch):\n",
    "        y[i, :ex.y_inds.size(0)].copy_(ex.y_inds)\n",
    "        y_mask[i, :ex.y_inds.size(0)].fill_(1)\n",
    "    \n",
    "    # for copying\n",
    "    y_in_x_inds = torch.FloatTensor(len(batch), max_output_length, max_input_length).zero_()\n",
    "    for i, ex in enumerate(batch):\n",
    "        y_in_x_inds[i, :ex.y_in_x_inds.size(0), :ex.y_in_x_inds.size(1)].copy_(ex.y_in_x_inds)\n",
    "\n",
    "    return x, x_lens, x_mask, y, y_mask, y_in_x_inds\n",
    "\n",
    "train_sampler = torch.utils.data.sampler.RandomSampler(train_dataset)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=100, ## the batch_size can be tuned\n",
    "    sampler=train_sampler,\n",
    "    num_workers=1,\n",
    "    collate_fn=vectorize\n",
    ")\n",
    "\n",
    "test_sampler = torch.utils.data.sampler.SequentialSampler(test_dataset)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1, ## the batch_size can be tuned\n",
    "    sampler=test_sampler,\n",
    "    num_workers=1,\n",
    "    collate_fn=vectorize\n",
    ")\n",
    "\n",
    "for x in train_loader:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 Build the seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stack bidirectional LSTM\n",
    "class StackBRNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers=1):\n",
    "        super(StackBRNN, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.rnns = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            input_dim = input_dim if i == 0 else hidden_dim * 2\n",
    "            self.rnns.append(nn.LSTM(input_dim, hidden_dim, bidirectional=True))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Transpose batch and sequence dims\n",
    "        x = x.transpose(0, 1) # (seq_len, batch_size, input_dim)\n",
    "\n",
    "        outputs = [x]\n",
    "        for i in range(self.num_layers):\n",
    "            rnn_input = outputs[-1]\n",
    "            rnn_output = self.rnns[i](rnn_input)[0]\n",
    "            outputs.append(rnn_output)\n",
    "\n",
    "        h_output = outputs[-1]\n",
    "\n",
    "        # Transpose back\n",
    "        h_output = h_output.transpose(0, 1) # (batch_size, seq_len, 2*hidden_dim)\n",
    "        \n",
    "        return h_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2.1: Define the basic seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, input_vocab, output_vocab, copying=False):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.input_vocab = input_vocab\n",
    "        self.output_vocab = output_vocab\n",
    "        self.in_vocab_size = len(self.input_vocab)\n",
    "        self.out_vocab_size = len(self.output_vocab)\n",
    "        \n",
    "        self.in_embedding = nn.Embedding(self.in_vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.encoder = StackBRNN(embedding_dim, hidden_dim)\n",
    "        \n",
    "        self.out_embedding = nn.Embedding(self.out_vocab_size, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        #Inputs: input, (h_0, c_0)\n",
    "        #Outputs: h_1, c_1\n",
    "        self.decoder = nn.LSTMCell(embedding_dim, hidden_dim) \n",
    "         \n",
    "        self.enc_to_dec = nn.Linear(hidden_dim*2, hidden_dim) # project encoding outupt\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_dim, self.out_vocab_size)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x_emb = self.in_embedding(x)\n",
    "        output = self.encoder(x_emb) # output: (batch_size, seq_len, hidden_dim*2)\n",
    "        return output\n",
    "    \n",
    "    def decode(self, h_prev):\n",
    "        out = self.output_layer(h_prev[0])\n",
    "        probs = F.softmax(out, dim=1)\n",
    "        \n",
    "        return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"attention.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttentionSeq2Seq(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, input_vocab, output_vocab, copying=False):\n",
    "        super(AttentionSeq2Seq, self).__init__()\n",
    "        self.input_vocab = input_vocab\n",
    "        self.output_vocab = output_vocab\n",
    "        self.in_vocab_size = len(self.input_vocab)\n",
    "        self.out_vocab_size = len(self.output_vocab)\n",
    "        self.copying = copying\n",
    "        \n",
    "        self.in_embedding = nn.Embedding(self.in_vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.encoder = StackBRNN(embedding_dim, hidden_dim)\n",
    "        \n",
    "        self.out_embedding = nn.Embedding(self.out_vocab_size, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        #Inputs: input, (h_0, c_0)\n",
    "        #Outputs: h_1, c_1\n",
    "        self.decoder = nn.LSTMCell(embedding_dim + hidden_dim*2, hidden_dim) # concatenate y_t and context_t\n",
    "        \n",
    "        self.enc_to_dec = nn.Linear(hidden_dim*2, hidden_dim) # project encoding outupt\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_dim + hidden_dim*2, self.out_vocab_size) # concatenate h_t and context_t\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x_emb = self.in_embedding(x) #(batch_size, seq_len, embedding_dim)\n",
    "        # map this part to glove\n",
    "        output = self.encoder(x_emb) # output: (batch_size, seq_len, hidden_dim*2)\n",
    "        return output\n",
    "    \n",
    "    def decode(self, encoder_outputs, encoder_proj_outputs, x_mask, h_prev):\n",
    "        # (batch_size, seq_len, hidden_dim) * (batch_size, hidden_dim, 1) - >(batch_size, seq_len, 1)\n",
    "        scores = torch.bmm(encoder_proj_outputs, h_prev[0].unsqueeze(2)).squeeze(2) # scores: (batch_size, seq_len)\n",
    "        scores.data.masked_fill_(x_mask.data, -float('inf'))\n",
    "        alpha = F.softmax(scores, dim=1)\n",
    "        # (batch_size, 1, seq_len) * (batch_size, seq_len, hidden_dim) - > (batch_size, 1, hidden_dim)\n",
    "        context_t = torch.bmm(alpha.unsqueeze(1), encoder_outputs).squeeze(1) # context_t: (batch_size, hidden_dim) \n",
    "        \n",
    "        out = self.output_layer(torch.cat([h_prev[0], context_t], 1))\n",
    "        \n",
    "        if self.copying: \n",
    "            probs = F.softmax(torch.cat([out, scores], 1), dim=1) # Appending scores over the input\n",
    "        else:\n",
    "            probs = F.softmax(out, dim=1)\n",
    "    \n",
    "        return probs, context_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2.2: Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can initialize and train the network:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Epoch = 0 | Loss = 57.08\n",
      "Epoch = 1 | Loss = 56.27\n",
      "Epoch = 2 | Loss = 54.54\n",
      "Epoch = 3 | Loss = 54.83\n",
      "Epoch = 4 | Loss = 54.30\n",
      "Epoch = 5 | Loss = 53.29\n",
      "Epoch = 6 | Loss = 52.99\n",
      "Epoch = 7 | Loss = 51.71\n",
      "Epoch = 8 | Loss = 51.19\n",
      "Epoch = 9 | Loss = 50.28\n",
      "Epoch = 10 | Loss = 48.98\n",
      "Epoch = 11 | Loss = 48.61\n",
      "Epoch = 12 | Loss = 46.74\n",
      "Epoch = 13 | Loss = 45.87\n",
      "Epoch = 14 | Loss = 45.61\n",
      "Epoch = 15 | Loss = 44.87\n",
      "Epoch = 16 | Loss = 43.64\n",
      "Epoch = 17 | Loss = 43.43\n",
      "Epoch = 18 | Loss = 42.61\n",
      "Epoch = 19 | Loss = 41.51\n",
      "Epoch = 20 | Loss = 40.32\n",
      "Epoch = 21 | Loss = 39.21\n",
      "Epoch = 22 | Loss = 38.53\n",
      "Epoch = 23 | Loss = 37.28\n",
      "Epoch = 24 | Loss = 37.08\n",
      "Epoch = 25 | Loss = 36.14\n",
      "Epoch = 26 | Loss = 36.83\n",
      "Epoch = 27 | Loss = 35.92\n",
      "Epoch = 28 | Loss = 34.51\n",
      "Epoch = 29 | Loss = 34.11\n",
      "Epoch = 30 | Loss = 33.74\n",
      "Epoch = 31 | Loss = 32.34\n",
      "Epoch = 32 | Loss = 32.47\n",
      "Epoch = 33 | Loss = 31.79\n",
      "Epoch = 34 | Loss = 31.93\n",
      "Epoch = 35 | Loss = 30.85\n",
      "Epoch = 36 | Loss = 30.69\n",
      "Epoch = 37 | Loss = 29.82\n",
      "Epoch = 38 | Loss = 28.60\n",
      "Epoch = 39 | Loss = 27.93\n",
      "Epoch = 40 | Loss = 27.24\n",
      "Epoch = 41 | Loss = 27.13\n",
      "Epoch = 42 | Loss = 26.35\n",
      "Epoch = 43 | Loss = 25.50\n",
      "Epoch = 44 | Loss = 24.55\n",
      "Epoch = 45 | Loss = 24.15\n",
      "Epoch = 46 | Loss = 23.66\n",
      "Epoch = 47 | Loss = 22.48\n",
      "Epoch = 48 | Loss = 21.97\n",
      "Epoch = 49 | Loss = 21.33\n",
      "Epoch = 50 | Loss = 21.12\n",
      "Epoch = 51 | Loss = 20.32\n",
      "Epoch = 52 | Loss = 19.67\n",
      "Epoch = 53 | Loss = 19.54\n",
      "Epoch = 54 | Loss = 18.61\n",
      "Epoch = 55 | Loss = 17.97\n",
      "Epoch = 56 | Loss = 17.99\n",
      "Epoch = 57 | Loss = 17.02\n",
      "Epoch = 58 | Loss = 16.92\n",
      "Epoch = 59 | Loss = 16.37\n",
      "Epoch = 60 | Loss = 16.05\n",
      "Epoch = 61 | Loss = 15.79\n",
      "Epoch = 62 | Loss = 15.10\n",
      "Epoch = 63 | Loss = 14.89\n",
      "Epoch = 64 | Loss = 14.68\n",
      "Epoch = 65 | Loss = 14.36\n",
      "Epoch = 66 | Loss = 14.01\n",
      "Epoch = 67 | Loss = 14.06\n",
      "Epoch = 68 | Loss = 13.48\n",
      "Epoch = 69 | Loss = 13.29\n",
      "Epoch = 70 | Loss = 13.18\n",
      "Epoch = 71 | Loss = 12.64\n",
      "Epoch = 72 | Loss = 12.61\n",
      "Epoch = 73 | Loss = 12.16\n",
      "Epoch = 74 | Loss = 11.71\n",
      "Epoch = 75 | Loss = 11.87\n",
      "Epoch = 76 | Loss = 11.61\n",
      "Epoch = 77 | Loss = 11.36\n",
      "Epoch = 78 | Loss = 11.15\n",
      "Epoch = 79 | Loss = 11.17\n",
      "Epoch = 80 | Loss = 10.88\n",
      "Epoch = 81 | Loss = 10.51\n",
      "Epoch = 82 | Loss = 10.37\n",
      "Epoch = 83 | Loss = 10.24\n",
      "Epoch = 84 | Loss = 10.18\n",
      "Epoch = 85 | Loss = 9.91\n",
      "Epoch = 86 | Loss = 9.79\n",
      "Epoch = 87 | Loss = 9.57\n",
      "Epoch = 88 | Loss = 9.31\n",
      "Epoch = 89 | Loss = 9.25\n",
      "Epoch = 90 | Loss = 9.06\n",
      "Epoch = 91 | Loss = 8.78\n",
      "Epoch = 92 | Loss = 8.63\n",
      "Epoch = 93 | Loss = 8.66\n",
      "Epoch = 94 | Loss = 8.44\n",
      "Epoch = 95 | Loss = 8.43\n",
      "Epoch = 96 | Loss = 8.31\n",
      "Epoch = 97 | Loss = 8.14\n",
      "Epoch = 98 | Loss = 7.95\n",
      "Epoch = 99 | Loss = 7.79\n",
      "Epoch = 100 | Loss = 7.58\n",
      "Epoch = 101 | Loss = 7.53\n",
      "Epoch = 102 | Loss = 7.18\n",
      "Epoch = 103 | Loss = 7.26\n",
      "Epoch = 104 | Loss = 7.27\n",
      "Epoch = 105 | Loss = 7.04\n",
      "Epoch = 106 | Loss = 6.96\n",
      "Epoch = 107 | Loss = 6.96\n",
      "Epoch = 108 | Loss = 6.68\n",
      "Epoch = 109 | Loss = 6.64\n",
      "Epoch = 110 | Loss = 6.54\n",
      "Epoch = 111 | Loss = 6.53\n",
      "Epoch = 112 | Loss = 6.39\n",
      "Epoch = 113 | Loss = 6.34\n",
      "Epoch = 114 | Loss = 6.03\n",
      "Epoch = 115 | Loss = 5.89\n",
      "Epoch = 116 | Loss = 5.86\n",
      "Epoch = 117 | Loss = 6.02\n",
      "Epoch = 118 | Loss = 5.84\n",
      "Epoch = 119 | Loss = 5.72\n",
      "Epoch = 120 | Loss = 5.40\n",
      "Epoch = 121 | Loss = 5.40\n",
      "Epoch = 122 | Loss = 5.40\n",
      "Epoch = 123 | Loss = 5.25\n",
      "Epoch = 124 | Loss = 5.17\n",
      "Epoch = 125 | Loss = 5.15\n",
      "Epoch = 126 | Loss = 5.06\n",
      "Epoch = 127 | Loss = 5.06\n",
      "Epoch = 128 | Loss = 4.96\n",
      "Epoch = 129 | Loss = 4.87\n",
      "Epoch = 130 | Loss = 4.79\n",
      "Epoch = 131 | Loss = 4.70\n",
      "Epoch = 132 | Loss = 4.62\n",
      "Epoch = 133 | Loss = 4.61\n",
      "Epoch = 134 | Loss = 4.54\n",
      "Epoch = 135 | Loss = 4.46\n",
      "Epoch = 136 | Loss = 4.41\n",
      "Epoch = 137 | Loss = 4.29\n",
      "Epoch = 138 | Loss = 4.25\n",
      "Epoch = 139 | Loss = 4.20\n",
      "Epoch = 140 | Loss = 4.15\n",
      "Epoch = 141 | Loss = 4.03\n",
      "Epoch = 142 | Loss = 3.99\n",
      "Epoch = 143 | Loss = 3.91\n",
      "Epoch = 144 | Loss = 4.03\n",
      "Epoch = 145 | Loss = 3.94\n",
      "Epoch = 146 | Loss = 3.97\n",
      "Epoch = 147 | Loss = 3.80\n",
      "Epoch = 148 | Loss = 3.67\n",
      "Epoch = 149 | Loss = 3.70\n"
=======
      "Epoch = 0 | Loss = 57.66\n",
      "Epoch = 1 | Loss = 56.69\n",
      "Epoch = 2 | Loss = 56.03\n",
      "Epoch = 3 | Loss = 56.19\n",
      "Epoch = 4 | Loss = 55.03\n",
      "Epoch = 5 | Loss = 53.86\n",
      "Epoch = 6 | Loss = 54.14\n",
      "Epoch = 7 | Loss = 53.26\n",
      "Epoch = 8 | Loss = 52.60\n",
      "Epoch = 9 | Loss = 52.23\n",
      "Epoch = 10 | Loss = 51.36\n",
      "Epoch = 11 | Loss = 49.15\n",
      "Epoch = 12 | Loss = 48.79\n",
      "Epoch = 13 | Loss = 47.60\n",
      "Epoch = 14 | Loss = 46.21\n",
      "Epoch = 15 | Loss = 45.68\n",
      "Epoch = 16 | Loss = 44.96\n",
      "Epoch = 17 | Loss = 44.28\n",
      "Epoch = 18 | Loss = 43.93\n",
      "Epoch = 19 | Loss = 41.83\n",
      "Epoch = 20 | Loss = 41.19\n",
      "Epoch = 21 | Loss = 39.90\n",
      "Epoch = 22 | Loss = 39.67\n",
      "Epoch = 23 | Loss = 39.05\n",
      "Epoch = 24 | Loss = 37.97\n",
      "Epoch = 25 | Loss = 36.82\n",
      "Epoch = 26 | Loss = 36.25\n",
      "Epoch = 27 | Loss = 35.76\n",
      "Epoch = 28 | Loss = 34.92\n",
      "Epoch = 29 | Loss = 34.31\n",
      "Epoch = 30 | Loss = 33.63\n",
      "Epoch = 31 | Loss = 33.21\n",
      "Epoch = 32 | Loss = 32.29\n",
      "Epoch = 33 | Loss = 31.58\n",
      "Epoch = 34 | Loss = 30.58\n",
      "Epoch = 35 | Loss = 30.18\n",
      "Epoch = 36 | Loss = 29.31\n",
      "Epoch = 37 | Loss = 28.55\n",
      "Epoch = 38 | Loss = 27.37\n",
      "Epoch = 39 | Loss = 26.46\n",
      "Epoch = 40 | Loss = 25.80\n",
      "Epoch = 41 | Loss = 25.15\n",
      "Epoch = 42 | Loss = 25.00\n",
      "Epoch = 43 | Loss = 23.97\n",
      "Epoch = 44 | Loss = 22.86\n",
      "Epoch = 45 | Loss = 23.00\n",
      "Epoch = 46 | Loss = 21.68\n",
      "Epoch = 47 | Loss = 21.11\n",
      "Epoch = 48 | Loss = 20.42\n",
      "Epoch = 49 | Loss = 19.70\n",
      "Epoch = 50 | Loss = 19.32\n",
      "Epoch = 51 | Loss = 18.81\n",
      "Epoch = 52 | Loss = 18.05\n",
      "Epoch = 53 | Loss = 18.24\n",
      "Epoch = 54 | Loss = 17.48\n",
      "Epoch = 55 | Loss = 16.86\n",
      "Epoch = 56 | Loss = 16.33\n",
      "Epoch = 57 | Loss = 16.19\n",
      "Epoch = 58 | Loss = 15.70\n",
      "Epoch = 59 | Loss = 15.12\n",
      "Epoch = 60 | Loss = 14.97\n",
      "Epoch = 61 | Loss = 14.72\n",
      "Epoch = 62 | Loss = 14.37\n",
      "Epoch = 63 | Loss = 13.89\n",
      "Epoch = 64 | Loss = 13.73\n",
      "Epoch = 65 | Loss = 13.49\n",
      "Epoch = 66 | Loss = 13.01\n",
      "Epoch = 67 | Loss = 13.26\n",
      "Epoch = 68 | Loss = 12.69\n",
      "Epoch = 69 | Loss = 12.39\n",
      "Epoch = 70 | Loss = 12.18\n",
      "Epoch = 71 | Loss = 12.03\n",
      "Epoch = 72 | Loss = 11.72\n",
      "Epoch = 73 | Loss = 11.55\n",
      "Epoch = 74 | Loss = 11.35\n",
      "Epoch = 75 | Loss = 11.28\n",
      "Epoch = 76 | Loss = 10.89\n",
      "Epoch = 77 | Loss = 10.86\n",
      "Epoch = 78 | Loss = 10.50\n",
      "Epoch = 79 | Loss = 10.49\n",
      "Epoch = 80 | Loss = 10.38\n",
      "Epoch = 81 | Loss = 10.18\n",
      "Epoch = 82 | Loss = 10.12\n",
      "Epoch = 83 | Loss = 9.60\n",
      "Epoch = 84 | Loss = 9.66\n",
      "Epoch = 85 | Loss = 9.41\n",
      "Epoch = 86 | Loss = 9.32\n",
      "Epoch = 87 | Loss = 9.28\n",
      "Epoch = 88 | Loss = 9.17\n",
      "Epoch = 89 | Loss = 9.03\n",
      "Epoch = 90 | Loss = 8.68\n",
      "Epoch = 91 | Loss = 8.69\n",
      "Epoch = 92 | Loss = 8.40\n",
      "Epoch = 93 | Loss = 8.46\n",
      "Epoch = 94 | Loss = 8.14\n",
      "Epoch = 95 | Loss = 8.14\n",
      "Epoch = 96 | Loss = 8.13\n",
      "Epoch = 97 | Loss = 7.91\n",
      "Epoch = 98 | Loss = 7.71\n",
      "Epoch = 99 | Loss = 7.62\n",
      "Epoch = 100 | Loss = 7.43\n",
      "Epoch = 101 | Loss = 7.30\n",
      "Epoch = 102 | Loss = 7.21\n",
      "Epoch = 103 | Loss = 7.21\n",
      "Epoch = 104 | Loss = 7.17\n",
      "Epoch = 105 | Loss = 7.11\n",
      "Epoch = 106 | Loss = 7.03\n",
      "Epoch = 107 | Loss = 6.98\n",
      "Epoch = 108 | Loss = 6.75\n",
      "Epoch = 109 | Loss = 6.62\n",
      "Epoch = 110 | Loss = 6.61\n",
      "Epoch = 111 | Loss = 6.43\n",
      "Epoch = 112 | Loss = 6.26\n",
      "Epoch = 113 | Loss = 6.16\n",
      "Epoch = 114 | Loss = 6.37\n",
      "Epoch = 115 | Loss = 6.23\n",
      "Epoch = 116 | Loss = 5.90\n",
      "Epoch = 117 | Loss = 5.98\n",
      "Epoch = 118 | Loss = 5.85\n",
      "Epoch = 119 | Loss = 5.91\n",
      "Epoch = 120 | Loss = 5.79\n",
      "Epoch = 121 | Loss = 5.66\n",
      "Epoch = 122 | Loss = 5.63\n",
      "Epoch = 123 | Loss = 5.42\n",
      "Epoch = 124 | Loss = 5.38\n",
      "Epoch = 125 | Loss = 5.29\n",
      "Epoch = 126 | Loss = 5.20\n",
      "Epoch = 127 | Loss = 5.13\n",
      "Epoch = 128 | Loss = 5.12\n",
      "Epoch = 129 | Loss = 5.09\n",
      "Epoch = 130 | Loss = 5.08\n",
      "Epoch = 131 | Loss = 5.03\n",
      "Epoch = 132 | Loss = 4.91\n",
      "Epoch = 133 | Loss = 4.88\n",
      "Epoch = 134 | Loss = 4.84\n",
      "Epoch = 135 | Loss = 4.65\n",
      "Epoch = 136 | Loss = 4.65\n",
      "Epoch = 137 | Loss = 4.60\n",
      "Epoch = 138 | Loss = 4.52\n",
      "Epoch = 139 | Loss = 4.44\n",
      "Epoch = 140 | Loss = 4.52\n",
      "Epoch = 141 | Loss = 4.48\n",
      "Epoch = 142 | Loss = 4.35\n",
      "Epoch = 143 | Loss = 4.24\n",
      "Epoch = 144 | Loss = 4.17\n",
      "Epoch = 145 | Loss = 4.17\n",
      "Epoch = 146 | Loss = 4.14\n",
      "Epoch = 147 | Loss = 4.04\n",
      "Epoch = 148 | Loss = 4.11\n",
      "Epoch = 149 | Loss = 4.04\n"
>>>>>>> b0685b9f8b78dd02ec25819e97848d60eeb666da
     ]
    }
   ],
   "source": [
    "def train(ex, model, optim):\n",
    "    model.train()\n",
    "    \n",
    "    x, x_lens, x_mask, y, y_mask, y_in_x_inds = ex\n",
    "    \n",
    "    # Variable(x.cuda()) if using GPU\n",
    "    x, x_lens, x_mask, y, y_mask, y_in_x_inds = Variable(x), Variable(x_lens), Variable(x_mask), Variable(y), Variable(y_mask), Variable(y_in_x_inds)\n",
    "    \n",
    "    encoder_outputs = model.encode(x) # (batch_size, seq_len, hidden_dim*2)\n",
    "    encoder_proj_outputs = model.enc_to_dec(encoder_outputs) # (batch_size, seq_len, hidden_dim)\n",
    "    \n",
    "    ###CHANGE: make use of x_lens to index the last hidden states\n",
    "    batch_size = x.size(0)\n",
    "    seq_len = x.size(1)\n",
    "    h_0 = torch.index_select(encoder_proj_outputs.view(batch_size*seq_len,-1),0,x_lens) # be careful when input sequences have paddings\n",
    "    \n",
    "    c_0 = Variable(torch.zeros(h_0.size(0), h_0.size(1)).zero_()) \n",
    "    hidden = (h_0, c_0)\n",
    "    \n",
    "    p_y_seq = []\n",
    "    for i in range(y.size(1)):\n",
    "        #output = model.decode(hidden) \n",
    "        #y_emb = model.out_embedding(y[:, i]) # y_emb: (batch_size, embedding_dim)        \n",
    "        #hidden = model.decoder(y_emb, hidden) # (h_t, c_t): (batch_size, hidden_dim)\n",
    "        \n",
    "        ###CHANGE: update the decode function, move the code that uses y[:, i] down\n",
    "        output, context_t = model.decode(encoder_outputs, encoder_proj_outputs, x_mask, hidden) # with attention\n",
    "        \n",
    "        ###compute the next hidden state using the current output y[:, i]\n",
    "        y_emb = model.out_embedding(y[:, i]) # y_emb: (batch_size, embedding_dim)\n",
    "        hidden = model.decoder(torch.cat([y_emb, context_t], 1), hidden) \n",
    "        \n",
    "        p_y_t = output.gather(1, y[:, i].unsqueeze(1)) # (batch_size, 1)\n",
    "        \n",
    "        if model.copying:\n",
    "            copy_dist = output[:, model.out_vocab_size:model.out_vocab_size + y_in_x_inds.size(2)] # (batch_size, input_len)\n",
    "            # (batch_size, 1, input_len), (batch_size, input_len, 1)\n",
    "            copying_p_y_t = torch.bmm(copy_dist.unsqueeze(1), y_in_x_inds[:, i].unsqueeze(2)).squeeze(2)\n",
    "            p_y_t = p_y_t + copying_p_y_t\n",
    "                \n",
    "        p_y_seq.append(p_y_t)\n",
    "\n",
    "    p_y_seq = torch.cat([_ for _ in p_y_seq], 1) # (batch_size, seq_len)\n",
    "    p_y_seq = torch.masked_select(p_y_seq, y_mask)\n",
    "    loss = -torch.sum(torch.log(p_y_seq))/y.size(0) # loss = -\\sum_i log p(y|x)\n",
    "\n",
    "    # Clear gradients and run backward\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients, max_norm * v/||v|| if ||v|| > max_norm\n",
    "    torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=10.0)\n",
    "\n",
    "    # Update parameters\n",
    "    optim.step()\n",
    "    \n",
    "    return loss.data[0]\n",
    "\n",
    "#model = Seq2Seq(50, 20, input_vocab, output_vocab)\n",
    "model = AttentionSeq2Seq(50, 20, input_vocab, output_vocab, True)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "# training loop\n",
    "n_epochs = 150\n",
    "for e in range(n_epochs):\n",
    "    train_loss = 0.0\n",
    "    for ex in train_loader:\n",
    "        l = train(ex, model, optim)\n",
    "        train_loss += l\n",
    "    print(\"Epoch = %d | Loss = %.2f\" % (e, train_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2.3: Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model, similar to training. Using greedy search to infer the most likely sequence output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "<__main__.ReaderDataset object at 0x1027fecf8>\n",
      "Gold:  max( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  min( WeatherHistory [ 'Temperature' ] ) <end> ) <end> ) <end> ) <end> ) <end>\n",
      "Gold:  mean( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  'Temperature' ] ) <end> ) <end> ) <end> ) <end> ) <end> ) <end> )\n",
      "Gold:  min( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  min( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ] ) <end> ) <end> )\n",
      "Gold:  predict( mod , 12 ) <end>\n",
      "Predict:  predict( mod , 12 ) <end> mod , 12 ) <end> mod , 12 )\n",
      "Gold:  max( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  min( WeatherHistory [ 'Temperature' ] ) <end> ) <end> ) <end> ) <end> ) <end>\n",
      "Gold:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end>\n",
      "Predict:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end> ) <end> )\n",
      "Gold:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end>\n",
      "Predict:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end> ) <end> WeatherHistory\n",
      "Gold:  mean( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'Temperature' ] ) <end> ) <end> )\n",
      "Gold:  predict( mod , 12 ) <end>\n",
      "Predict:  UNK mod , 12 ) <end> ) <end> mod , 12 ) <end> ) <end>\n",
      "Gold:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end>\n",
      "Predict:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end> WeatherHistory [ 'FellingTemperature'\n",
      "Gold:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end>\n",
      "Predict:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end> ) <end> )\n",
      "Gold:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end>\n",
      "Predict:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end> ) <end> )\n",
      "Gold:  predict( mod , 12 ) <end>\n",
      "Predict:  predict( mod , 12 ) <end> mod , 12 ) <end> mod , 12 )\n",
      "Gold:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end>\n",
      "Predict:  UNK ] , WeatherHistory [ 'Humidity' ] ) <end> WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Gold:  predict( mod , 12 ) <end>\n",
      "Predict:  UNK , WeatherHistory [ 'Humidity' ] ) <end> ) <end> WeatherHistory [ 'Humidity' ] )\n",
      "Gold:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end>\n",
      "Predict:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end> WeatherHistory [ 'FellingTemperature'\n",
      "Gold:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  UNK ] , WeatherHistory [ 'Humidity' ] ) <end> WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Gold:  max( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  min( WeatherHistory [ 'Temperature' ] ) <end> ) <end> ) <end> ) <end> ) <end>\n",
      "Gold:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  UNK ] , WeatherHistory [ 'Humidity' ] ) <end> ) <end> ) <end> ) <end>\n",
      "Gold:  mean( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  min( WeatherHistory [ 'Temperature' ] ) <end> ) <end> ) <end> ) <end> ) <end>\n",
      "Gold:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end>\n",
      "Predict:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end> ) <end> )\n",
      "Gold:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  UNK ] , WeatherHistory [ 'Humidity' ] ) <end> WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Gold:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end> WeatherHistory [ 'FellingTemperature'\n",
      "Gold:  max( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  min( WeatherHistory [ 'Temperature' ] ) <end> ) <end> ) <end> ) <end> ) <end>\n",
      "Gold:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  UNK ] , WeatherHistory [ 'Humidity' ] ) <end> ) <end> ) <end> ) <end>\n",
      "Gold:  max( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  UNK 'Temperature' ] ) <end> ) <end> ) <end> ) <end> ) <end> ) <end>\n",
      "Gold:  mean( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  mean( WeatherHistory [ 'Temperature' ] ) <end> ) <end> ) <end> ) <end> ) <end>\n",
      "Gold:  min( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  min( WeatherHistory [ 'Temperature' ] ) <end> ) <end> ) <end> ) <end> ) <end>\n",
      "Gold:  max( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  min( WeatherHistory [ 'Temperature' ] ) <end> ) <end> ) <end> ) <end> ) <end>\n",
      "Gold:  predict( mod , 12 ) <end>\n",
      "Predict:  predict( mod , 12 ) <end> ) <end> ) <end> ) <end> ) <end> )\n",
      "Gold:  predict( mod , 12 ) <end>\n",
      "Predict:  min( WeatherHistory [ 'Temperature' ] ) <end> ) <end> ) <end> ) <end> ) <end>\n",
      "Gold:  mean( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  UNK 'Temperature' ] ) <end> ) <end> ) <end> ) <end> ) <end> ) <end>\n",
      "Gold:  max( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  min( WeatherHistory [ 'Temperature' ] ) <end> ) <end> ) <end> ) <end> ) <end>\n",
      "Gold:  mean( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  min( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ]\n",
      "Gold:  max( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  UNK 'Temperature' ] ) <end> ) <end> ) <end> ) <end> ) <end> ) <end>\n",
      "Gold:  mean( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  min( WeatherHistory [ 'Temperature' ] ) <end> ) <end> ) <end> ) <end> ) <end>\n",
      "Gold:  max( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  max( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Temperature' ] ) <end> ) <end> )\n",
      "Gold:  mean( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  UNK 'Temperature' ] ) <end> ) <end> ) <end> ) <end> ) <end> ) <end>\n",
      "Gold:  min( WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  UNK ] , WeatherHistory [ 'Humidity' ] ) <end> ) <end> ) <end> ) <end>\n",
      "Gold:  min( WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  UNK ] , WeatherHistory [ 'Humidity' ] ) <end> ) <end> ) <end> ) <end>\n",
      "Test accuracy: 0.3\n"
=======
      "Gold:  max( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  min( WeatherHistory [ 'Temperature' ] ) <end> <end> <end> 'Temperature' ] ) <end> <end> <end>\n",
      "Gold:  mean( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  min( WeatherHistory [ 'Temperature' ] ) <end> <end> <end> 'Temperature' ] ) <end> <end> <end>\n",
      "Gold:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end>\n",
      "Predict:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end> <end> <end> [\n",
      "Gold:  max( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  min( WeatherHistory [ 'Temperature' ] ) <end> <end> <end> 'Temperature' ] ) <end> <end> <end>\n",
      "Gold:  predict( mod , 12 ) <end>\n",
      "Predict:  predict( mod , 12 ) <end> <end> <end> 'Temperature' ] ) <end> <end> <end> )\n",
      "Gold:  min( WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  min( WeatherHistory [ 'Temperature' ] ) <end> <end> 'Temperature' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  predict( mod , 12 ) <end>\n",
      "Predict:  predict( mod ) <end> <end> <end> <end> 'Temperature' ] ) <end> <end> <end> <end> 'Temperature'\n",
      "Gold:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  predict( mod , 12 ) <end>\n",
      "Predict:  predict( mod , 12 ) <end> <end> <end> <end> <end> ) <end> <end> <end> )\n",
      "Gold:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end>\n",
      "Predict:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  predict( mod , 12 ) <end>\n",
      "Predict:  predict( mod , 12 ) <end> <end> <end> ) <end> <end> <end> 'Temperature' ] ,\n",
      "Gold:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end>\n",
      "Predict:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end>\n",
      "Predict:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  predict( mod , 12 ) <end>\n",
      "Predict:  predict( mod , 12 ) <end> <end> <end> <end> ) <end> <end> 'Temperature' ] )\n",
      "Gold:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end>\n",
      "Predict:  max( WeatherHistory [ 'Temperature' ] ) <end> <end> 'Temperature' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  predict( mod , 12 ) <end>\n",
      "Predict:  predict( mod , 12 ) <end> <end> <end> <end> <end> ) <end> <end> <end> <end>\n",
      "Gold:  min( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  max( WeatherHistory [ 'Temperature' ] ) <end> <end> <end> 'Temperature' ] ) <end> <end> <end>\n",
      "Gold:  min( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  max( WeatherHistory [ 'Temperature' ] ) <end> <end> <end> 'Temperature' ] ) <end> <end> <end>\n",
      "Gold:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  predict( mod , 12 ) <end> ) <end> <end> ) <end> <end> ) <end> <end>\n",
      "Gold:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end>\n",
      "Predict:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end> <end> ) <end>\n",
      "Gold:  mean( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  max( WeatherHistory [ 'Temperature' ] ) <end> <end> 'Temperature' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  predict( mod , 12 ) <end>\n",
      "Predict:  predict( mod , 12 ) <end> <end> <end> <end> ) <end> <end> 'Temperature' ] ,\n",
      "Gold:  min( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  max( WeatherHistory [ 'Temperature' ] ) <end> <end> <end> 'Temperature' ] ) <end> <end> <end>\n",
      "Gold:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end>\n",
      "Predict:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  mean( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  max( WeatherHistory [ 'Temperature' ] ) <end> <end> <end> 'Temperature' ] ) <end> <end> <end>\n",
      "Gold:  mean( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  max( WeatherHistory [ 'Temperature' ] ) <end> <end> <end> 'Temperature' ] ) <end> <end> <end>\n",
      "Gold:  min( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  min( WeatherHistory [ 'Temperature' ] ) <end> <end> <end> 'Temperature' ] ) <end> <end> <end>\n",
      "Gold:  max( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  cor( WeatherHistroy [ 'Temperature' ] ) <end> <end> [ 'Temperature' ] ) <end> <end> <end>\n",
      "Gold:  min( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  max( WeatherHistory [ 'Temperature' ] ) <end> <end> <end> 'Temperature' ] ) <end> <end> <end>\n",
      "Gold:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  min( WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  min( WeatherHistory [ 'Temperature' ] ) <end> <end> 'Temperature' ] ) <end> <end> <end> 'Temperature'\n",
      "Gold:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  min( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  min( WeatherHistory [ 'Temperature' ] ) <end> <end> <end> 'Temperature' ] ) <end> <end> <end>\n",
      "Gold:  predict( mod , 12 ) <end>\n",
      "Predict:  predict( mod ) <end> <end> <end> <end> 'Temperature' ] ) <end> <end> <end> <end> 'Temperature'\n",
      "Gold:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end>\n",
      "Predict:  lm( WeatherHistory [ 'Temperature' ] , WeatherHistory [ 'Humidity' ] ) <end> <end> 'Temperature' ]\n",
      "Gold:  max( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  max( WeatherHistory [ 'Temperature' ] ) <end> <end> <end> 'Temperature' ] ) <end> <end> <end>\n",
      "Gold:  mean( WeatherHistory [ 'Temperature' ] ) <end>\n",
      "Predict:  max( WeatherHistory [ 'Temperature' ] ) <end> <end> [ 'Temperature' ] ) <end> <end> <end>\n",
      "Gold:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end>\n",
      "Predict:  cor( WeatherHistroy [ 'Temperature' ] , WeatherHistory [ 'FellingTemperature' ] ) <end> <end> <end> 'Temperature'\n",
      "Test accuracy: 0.5\n"
>>>>>>> b0685b9f8b78dd02ec25819e97848d60eeb666da
     ]
    }
   ],
   "source": [
    "def test_batch(data_loader, model, max_len=15):\n",
    "    model.eval()\n",
    "    \n",
    "    num_correct = 0\n",
    "    for ex in data_loader:\n",
    "        x, x_lens, x_mask, y, y_mask, y_in_x_inds = ex \n",
    "        \n",
    "        x, x_lens, x_mask = Variable(x), Variable(x_lens), Variable(x_mask)\n",
    "    \n",
    "        encoder_outputs = model.encode(x) # (batch_size, seq_len, hidden_dim*2)\n",
    "        encoder_proj_outputs = model.enc_to_dec(encoder_outputs) # (batch_size, seq_len, hidden_dim)\n",
    "        \n",
    "        ###CHANGE: make use of x_lens to index the last hidden states\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = x.size(1)\n",
    "        h_0 = torch.index_select(encoder_proj_outputs.view(batch_size*seq_len,-1),0,x_lens) # be careful when input sequences have paddings\n",
    "    \n",
    "        c_0 = Variable(torch.zeros(h_0.size(0), h_0.size(1)).zero_()) \n",
    "        hidden = (h_0, c_0)\n",
    "        \n",
    "        ###CHANGE: start with empty prediction\n",
    "        seq = []\n",
    "        for i in range(max_len):\n",
    "            #output = model.decode(hidden) \n",
    "            \n",
    "            ###CHANGE: update the decode function, move the code that uses y[:, i] down\n",
    "            output, context_t = model.decode(encoder_outputs, encoder_proj_outputs, x_mask, hidden) # with attention\n",
    "        \n",
    "            sampleLogprobs, it = torch.max(output.data, 1)\n",
    "            y_t = it.view(-1).long()\n",
    "            seq.append(y_t)\n",
    "            \n",
    "            if model.copying:\n",
    "                new_y_t = []\n",
    "                for j in range(y_t.size(0)):\n",
    "                    if y_t[j] < model.out_vocab_size:\n",
    "                        new_y_t.append(y_t[j])\n",
    "                    else:\n",
    "                        k = x.data[j, y_t[j]-model.out_vocab_size]\n",
    "                        w = model.input_vocab.get_word(k)\n",
    "                        new_k = model.output_vocab.get_index(w)\n",
    "                        new_y_t.append(new_k)\n",
    "                y_t = torch.LongTensor(new_y_t)\n",
    "            \n",
    "            ###compute the next hidden state using the current output y_t\n",
    "            y_prev = Variable(y_t)\n",
    "            y_emb = model.out_embedding(y_prev) # y_emb: (batch_size, embedding_dim)\n",
    "            hidden = model.decoder(torch.cat([y_emb, context_t], 1), hidden) \n",
    "            \n",
    "            #hidden = model.decoder(y_emb, hidden)\n",
    "        \n",
    "        pred_y = torch.cat([_.unsqueeze(1) for _ in seq], 1)\n",
    "        \n",
    "        for idx in range(batch_size):\n",
    "            gold_toks = []\n",
    "            for wi in y[idx].tolist():\n",
    "                gold_toks.append(model.output_vocab.get_word(wi))\n",
    "            print(\"Gold: \", ' '.join(gold_toks))\n",
    "        \n",
    "            pred_toks = []\n",
    "            for wi in pred_y[idx].tolist():\n",
    "                #w = model.output_vocab.get_word(wi)\n",
    "            \n",
    "                if wi < model.out_vocab_size:\n",
    "                    w = model.output_vocab.get_word(wi)\n",
    "                else:\n",
    "                    w = model.input_vocab.get_word(x.data[idx][wi-model.out_vocab_size])\n",
    "                    #print(\"copying \", w)\n",
    "                    \n",
    "                pred_toks.append(w)\n",
    "                \n",
    "            print(\"Predict: \",' '.join(pred_toks))\n",
    "            \n",
    "            for i in range(len(gold_toks)):\n",
    "                g_tok = gold_toks[i]\n",
    "                p_tok = pred_toks[i]\n",
    "                if (g_tok != p_tok):\n",
    "                    break\n",
    "                elif (g_tok == \"<end>\"):\n",
    "                    num_correct += 1\n",
    "                    \n",
    "                    \n",
    "    print(\"Test accuracy: {}\".format(num_correct / len(data_loader)))\n",
    "\n",
    "    \n",
    "print(test_loader.dataset)\n",
    "        \n",
    "test_batch(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
